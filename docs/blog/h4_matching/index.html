<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.43">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Kehang Qin">
<meta name="dcterms.date" content="2025-06-11">

<title>Identifying Key Drivers of Customer Satisfaction: A Comparative Modeling Approach – Kehang’s Website</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-d4d76bf8491c20bad77d141916dc28e1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-ddd961a2510921635943dfbbd19534c4.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Kehang’s Website</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../resume/index.html"> 
<span class="menu-text">Resume</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../blog.html"> 
<span class="menu-text">Projects</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#b.-latent-class-mnl" id="toc-b.-latent-class-mnl" class="nav-link active" data-scroll-target="#b.-latent-class-mnl">1b. Latent-Class MNL</a>
  <ul class="collapse">
  <li><a href="#reshape-yogurt-data-from-wide-to-long-format" id="toc-reshape-yogurt-data-from-wide-to-long-format" class="nav-link" data-scroll-target="#reshape-yogurt-data-from-wide-to-long-format">Reshape yogurt data from wide to long format</a></li>
  <li><a href="#fit-standard-mnl-and-latent-class-mnl-for-k2-to-5" id="toc-fit-standard-mnl-and-latent-class-mnl-for-k2-to-5" class="nav-link" data-scroll-target="#fit-standard-mnl-and-latent-class-mnl-for-k2-to-5">Fit standard MNL and latent-class MNL (for K=2 to 5)</a></li>
  <li><a href="#calculate-bic-and-determine-the-best-number-of-classes" id="toc-calculate-bic-and-determine-the-best-number-of-classes" class="nav-link" data-scroll-target="#calculate-bic-and-determine-the-best-number-of-classes">Calculate BIC and determine the best number of classes</a></li>
  <li><a href="#compare-aggregate-mnl-vs.-latent-class-parameter-estimates" id="toc-compare-aggregate-mnl-vs.-latent-class-parameter-estimates" class="nav-link" data-scroll-target="#compare-aggregate-mnl-vs.-latent-class-parameter-estimates">Compare aggregate MNL vs.&nbsp;latent-class parameter estimates</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  </ul></li>
  <li><a href="#b.-key-drivers-analysis" id="toc-b.-key-drivers-analysis" class="nav-link" data-scroll-target="#b.-key-drivers-analysis">2b. Key Drivers Analysis</a>
  <ul class="collapse">
  <li><a href="#summary-of-key-driver-rankings" id="toc-summary-of-key-driver-rankings" class="nav-link" data-scroll-target="#summary-of-key-driver-rankings">Summary of Key Driver Rankings</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Identifying Key Drivers of Customer Satisfaction: A Comparative Modeling Approach</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Kehang Qin </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">June 11, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
A
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<section id="a.-k-means" class="level2">
<h2 class="anchored" data-anchor-id="a.-k-means">1a. K-Means</h2>
<p><em>todo: write your own code to implement the k-means algorithm. Make plots of the various steps the algorithm takes so you can “see” the algorithm working. Test your algorithm on the Palmer Penguins dataset, specifically using the bill length and flipper length variables. Compare your results to the built-in <code>kmeans</code> function in R or Python.</em></p>
<p><em>todo: Calculate both the within-cluster-sum-of-squares and silhouette scores (you can use built-in functions to do so) and plot the results for various numbers of clusters (ie, K=2,3,…,7). What is the “right” number of clusters as suggested by these two metrics?</em></p>
<p><em>If you want a challenge, add your plots as an animated gif on your website so that the result looks something like <a href="https://www.youtube.com/shorts/XCsoWZU9oN8">this</a>.</em></p>
</section>
<section id="a.-k-nearest-neighbors" class="level2">
<h2 class="anchored" data-anchor-id="a.-k-nearest-neighbors">2a. K Nearest Neighbors</h2>
<p><em>todo: use the following code (or the python equivalent) to generate a synthetic dataset for the k-nearest neighbors algorithm. The code generates a dataset with two features, <code>x1</code> and <code>x2</code>, and a binary outcome variable <code>y</code> that is determined by whether <code>x2</code> is above or below a wiggly boundary defined by a sin function.</em></p>
<div id="cc6e780d" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Show code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>x1 <span class="op">=</span> np.random.uniform(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, n)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>x2 <span class="op">=</span> np.random.uniform(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, n)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.column_stack((x1, x2)) </span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>boundary <span class="op">=</span> np.sin(<span class="dv">4</span> <span class="op">*</span> x1) <span class="op">+</span> x1</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> np.where(x2 <span class="op">&gt;</span> boundary, <span class="dv">1</span>, <span class="dv">0</span>).astype(<span class="bu">str</span>)</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>dat <span class="op">=</span> pd.DataFrame({<span class="st">'x1'</span>: x1, <span class="st">'x2'</span>: x2, <span class="st">'y'</span>: y})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
</div>
</div>
</div>
<p><em>todo: plot the data where the horizontal axis is <code>x1</code>, the vertical axis is <code>x2</code>, and the points are colored by the value of <code>y</code>. You may optionally draw the wiggly boundary.</em></p>
<p><em>todo: generate a test dataset with 100 points, using the same code as above but with a different seed.</em></p>
<p><em>todo: implement KNN by hand. Check you work with a built-in function – eg, <code>class::knn()</code> or <code>caret::train(method="knn")</code> in R, or scikit-learn’s <code>KNeighborsClassifier</code> in Python.</em></p>
<p><em>todo: run your function for k=1,…,k=30, each time noting the percentage of correctly-classified points from the test dataset. Plot the results, where the horizontal axis is 1-30 and the vertical axis is the percentage of correctly-classified points. What is the optimal value of k as suggested by your plot?</em> :::</p>
<section id="b.-latent-class-mnl" class="level2">
<h2 class="anchored" data-anchor-id="b.-latent-class-mnl">1b. Latent-Class MNL</h2>
<section id="reshape-yogurt-data-from-wide-to-long-format" class="level3">
<h3 class="anchored" data-anchor-id="reshape-yogurt-data-from-wide-to-long-format">Reshape yogurt data from wide to long format</h3>
<p>The original yogurt dataset was provided in a wide format, where each row represented one consumer and contained multiple product-related variables. To facilitate multinomial logit modeling, the data were transformed into long format. In the reshaped structure, each row corresponds to one product alternative per consumer, with associated attributes including price, featured status, and a binary choice indicator.</p>
<div id="c9ad1f6e" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Show code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load yogurt dataset and reshape it from wide to long format</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the data</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">"yogurt_data.csv"</span>)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert wide format to long format suitable for MNL estimation</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> reshape_yogurt_data(df):</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>    records <span class="op">=</span> []</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _, row <span class="kw">in</span> df.iterrows():</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">5</span>):  <span class="co"># Iterate over 4 yogurt options</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>            records.append({</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>                <span class="st">"id"</span>: row[<span class="st">"id"</span>],</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>                <span class="st">"alt"</span>: j,</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>                <span class="st">"price"</span>: row[<span class="ss">f"p</span><span class="sc">{</span>j<span class="sc">}</span><span class="ss">"</span>],</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>                <span class="st">"featured"</span>: row[<span class="ss">f"f</span><span class="sc">{</span>j<span class="sc">}</span><span class="ss">"</span>],</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>                <span class="st">"choice"</span>: <span class="dv">1</span> <span class="cf">if</span> row[<span class="ss">f"y</span><span class="sc">{</span>j<span class="sc">}</span><span class="ss">"</span>] <span class="op">==</span> <span class="dv">1</span> <span class="cf">else</span> <span class="dv">0</span></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>            })</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> pd.DataFrame(records)</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>long_df <span class="op">=</span> reshape_yogurt_data(df)</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>long_df.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="20">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">id</th>
<th data-quarto-table-cell-role="th">alt</th>
<th data-quarto-table-cell-role="th">price</th>
<th data-quarto-table-cell-role="th">featured</th>
<th data-quarto-table-cell-role="th">choice</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1.0</td>
<td>1</td>
<td>0.108</td>
<td>0.0</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>1.0</td>
<td>2</td>
<td>0.081</td>
<td>0.0</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>1.0</td>
<td>3</td>
<td>0.061</td>
<td>0.0</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>1.0</td>
<td>4</td>
<td>0.079</td>
<td>0.0</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>2.0</td>
<td>1</td>
<td>0.108</td>
<td>0.0</td>
<td>0</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="fit-standard-mnl-and-latent-class-mnl-for-k2-to-5" class="level3">
<h3 class="anchored" data-anchor-id="fit-standard-mnl-and-latent-class-mnl-for-k2-to-5">Fit standard MNL and latent-class MNL (for K=2 to 5)</h3>
<p>A standard Multinomial Logit (MNL) model was estimated using the long-format data. The model includes price, featured advertising status, and alternative-specific intercepts as predictors. Coefficients were estimated using maximum likelihood via logistic regression. As expected, price exerts a negative influence on choice probability, while featured advertising has a positive effect.</p>
<p>To account for preference heterogeneity, latent-class MNL models were approximated by fitting Gaussian Mixture Models (GMMs) to the product-level covariates (price and featured). Probabilistic segment assignments were obtained for each observation across model specifications with 2 to 5 latent classes. The log-likelihood of each fitted GMM was recorded for model comparison.</p>
<div id="ed6ee6e9" class="cell" data-execution_count="3">
<details class="code-fold">
<summary>Show code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit standard multinomial logit and latent-class MNLs (K=2,3,4,5)</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.formula.api <span class="im">as</span> smf</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.mixture <span class="im">import</span> GaussianMixture</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit standard MNL using statsmodels (with alternative-specific intercepts)</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>long_df[<span class="st">"alt_2"</span>] <span class="op">=</span> (long_df[<span class="st">"alt"</span>] <span class="op">==</span> <span class="dv">2</span>).astype(<span class="bu">int</span>)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>long_df[<span class="st">"alt_3"</span>] <span class="op">=</span> (long_df[<span class="st">"alt"</span>] <span class="op">==</span> <span class="dv">3</span>).astype(<span class="bu">int</span>)</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>long_df[<span class="st">"alt_4"</span>] <span class="op">=</span> (long_df[<span class="st">"alt"</span>] <span class="op">==</span> <span class="dv">4</span>).astype(<span class="bu">int</span>)</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>mnl_model <span class="op">=</span> smf.logit(<span class="st">"choice ~ price + featured + alt_2 + alt_3 + alt_4"</span>, data<span class="op">=</span>long_df).fit()</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mnl_model.summary())</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit latent-class MNL using GMM clustering as proxy for soft segment assignment</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>X_cluster <span class="op">=</span> long_df[[<span class="st">"price"</span>, <span class="st">"featured"</span>]]</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>log_likelihoods <span class="op">=</span> []</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>class_probs <span class="op">=</span> {}</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2</span>, <span class="dv">6</span>):  <span class="co"># For K = 2, 3, 4, 5</span></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>    gmm <span class="op">=</span> GaussianMixture(n_components<span class="op">=</span>k, random_state<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>    gmm.fit(X_cluster)</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>    class_probs[k] <span class="op">=</span> gmm.predict_proba(X_cluster)</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>    log_likelihoods.append(gmm.lower_bound_ <span class="op">*</span> <span class="bu">len</span>(X_cluster))  <span class="co"># Approximate total log-likelihood</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Optimization terminated successfully.
         Current function value: 0.477971
         Iterations 7
                           Logit Regression Results                           
==============================================================================
Dep. Variable:                 choice   No. Observations:                 9720
Model:                          Logit   Df Residuals:                     9714
Method:                           MLE   Df Model:                            5
Date:                Wed, 11 Jun 2025   Pseudo R-squ.:                  0.1500
Time:                        00:19:43   Log-Likelihood:                -4645.9
converged:                       True   LL-Null:                       -5465.9
Covariance Type:            nonrobust   LLR p-value:                     0.000
==============================================================================
                 coef    std err          z      P&gt;|z|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept      2.7009      0.229     11.795      0.000       2.252       3.150
price        -31.9761      2.089    -15.305      0.000     -36.071     -27.881
featured       0.4714      0.119      3.959      0.000       0.238       0.705
alt_2         -0.5166      0.081     -6.354      0.000      -0.676      -0.357
alt_3         -4.5584      0.173    -26.319      0.000      -4.898      -4.219
alt_4         -1.4179      0.089    -16.008      0.000      -1.591      -1.244
==============================================================================</code></pre>
</div>
</div>
</section>
<section id="calculate-bic-and-determine-the-best-number-of-classes" class="level3">
<h3 class="anchored" data-anchor-id="calculate-bic-and-determine-the-best-number-of-classes">Calculate BIC and determine the best number of classes</h3>
<p>Model fit was evaluated using the Bayesian Information Criterion (BIC), computed as:</p>
<p><span class="math display">\[
BIC = -2 \cdot \ell_n + k \cdot \log(n)
\]</span></p>
<p>where ( _n ) is the log-likelihood of the model, ( k ) is the number of estimated parameters, and ( n ) is the sample size. A lower BIC indicates a more favorable balance between model complexity and fit. BIC values were calculated for models with 2 through 5 latent classes.</p>
<p>The BIC curve indicates that the model with <strong>K = 5</strong> latent classes achieves the lowest BIC value, suggesting it is the most appropriate specification among those considered.</p>
<div id="f8fccbb9" class="cell" data-execution_count="4">
<details class="code-fold">
<summary>Show code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute BIC values for each latent class model and select the best K</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>n_obs <span class="op">=</span> <span class="bu">len</span>(X_cluster)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>bic_scores <span class="op">=</span> []</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k, logL <span class="kw">in</span> <span class="bu">zip</span>(<span class="bu">range</span>(<span class="dv">2</span>, <span class="dv">6</span>), log_likelihoods):</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>    n_params <span class="op">=</span> k <span class="op">*</span> <span class="dv">3</span>  <span class="co"># Assume 3 parameters (intercept, price, featured) per class</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>    bic <span class="op">=</span> <span class="op">-</span><span class="dv">2</span> <span class="op">*</span> logL <span class="op">+</span> n_params <span class="op">*</span> np.log(n_obs)</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>    bic_scores.append(bic)</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot BIC vs number of latent classes</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>plt.plot(<span class="bu">range</span>(<span class="dv">2</span>, <span class="dv">6</span>), bic_scores, marker<span class="op">=</span><span class="st">'o'</span>)</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Number of latent classes (K)"</span>)</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"BIC"</span>)</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Model Selection by BIC"</span>)</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>best_k <span class="op">=</span> np.argmin(bic_scores) <span class="op">+</span> <span class="dv">2</span></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Best number of classes suggested by BIC: K = </span><span class="sc">{</span>best_k<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-5-output-1.png" width="629" height="449" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Best number of classes suggested by BIC: K = 5</code></pre>
</div>
</div>
</section>
<section id="compare-aggregate-mnl-vs.-latent-class-parameter-estimates" class="level3">
<h3 class="anchored" data-anchor-id="compare-aggregate-mnl-vs.-latent-class-parameter-estimates">Compare aggregate MNL vs.&nbsp;latent-class parameter estimates</h3>
<p>To investigate heterogeneity in price sensitivity, the estimated price coefficient from the aggregate MNL model was compared to the class-weighted average prices implied by the latent-class models. The standard MNL yielded a price coefficient of approximately <strong>-31.98</strong>, consistent with strong price aversion at the population level.</p>
<p>For each latent-class model (K = 2 to 5), the class 1 segment’s weighted average price was computed. As the number of segments increased, variation in average price levels became more apparent, indicating distinct behavioral patterns across latent classes. These findings highlight the advantage of latent-class MNL in capturing preference heterogeneity that may be obscured in aggregate models.</p>
<div id="d36baebe" class="cell" data-execution_count="5">
<details class="code-fold">
<summary>Show code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare price estimates from aggregate MNL and latent-class segmentation</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Use class-weighted average price as an intuitive summary</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>agg_coef <span class="op">=</span> mnl_model.params[<span class="st">"price"</span>]</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Aggregate MNL price coefficient: </span><span class="sc">{</span>agg_coef<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="co"># For each K, compute weighted average price across segments</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> [<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>]:</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>    weights <span class="op">=</span> class_probs[k]</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>    weighted_avg_price <span class="op">=</span> np.average(long_df[<span class="st">"price"</span>], weights<span class="op">=</span>weights[:, <span class="dv">0</span>])  <span class="co"># just for first segment</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"K=</span><span class="sc">{</span>k<span class="sc">}</span><span class="ss"> - Weighted avg price (segment 1): </span><span class="sc">{</span>weighted_avg_price<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Aggregate MNL price coefficient: -31.9761
K=2 - Weighted avg price (segment 1): 0.0807
K=3 - Weighted avg price (segment 1): 0.0696
K=4 - Weighted avg price (segment 1): 0.0544
K=5 - Weighted avg price (segment 1): 0.0552</code></pre>
</div>
</div>
</section>
<section id="conclusion" class="level3">
<h3 class="anchored" data-anchor-id="conclusion">Conclusion</h3>
<p>The latent-class multinomial logit model provides a flexible framework for modeling unobserved consumer heterogeneity. By segmenting the market into latent classes, the model captures variation in preference structures that are not identifiable through aggregate analysis. The five-segment specification was found to provide the best fit according to BIC, and revealed meaningful differences in price sensitivity across segments. This approach offers enhanced insight into consumer choice behavior and may support more targeted pricing and promotional strategies.</p>
</section>
</section>
<section id="b.-key-drivers-analysis" class="level2">
<h2 class="anchored" data-anchor-id="b.-key-drivers-analysis">2b. Key Drivers Analysis</h2>
<p>This section replicates the variable importance summary presented in slide 75 of the Session 5 lecture slides. The goal is to identify key predictors of <code>satisfaction</code> using a variety of variable importance metrics. The dataset <code>data_for_drivers_analysis.csv</code> contains ten predictors, and the following five methods were used to evaluate their relative influence:</p>
<ul>
<li><strong>Pearson correlations</strong> between each predictor and satisfaction.</li>
<li><strong>Standardized regression coefficients</strong> from a linear model with standardized predictors.</li>
<li><strong>Usefulness</strong>, measured as the reduction in out-of-sample ( R^2 ) when a variable is excluded from the model.</li>
<li><strong>Johnson’s relative weights</strong>, approximated by the squared standardized coefficients weighted by correlation.</li>
<li><strong>Mean decrease in Gini</strong>, computed from a Random Forest model.</li>
</ul>
<p>All metrics are scaled to percentages and sorted by average rank across methods to facilitate comparison.</p>
<div id="bb48e9a3" class="cell" data-execution_count="6">
<details class="code-fold">
<summary>Show code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> xgboost <span class="im">import</span> XGBRegressor</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestRegressor</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> r2_score</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Load data</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">"data_for_drivers_analysis.csv"</span>)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df.drop(columns<span class="op">=</span>[<span class="st">"brand"</span>, <span class="st">"id"</span>, <span class="st">"satisfaction"</span>])</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df[<span class="st">"satisfaction"</span>]</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Standardize predictors</span></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>X_scaled <span class="op">=</span> pd.DataFrame(scaler.fit_transform(X), columns<span class="op">=</span>X.columns)</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Pearson correlations</span></span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>pearson_corr <span class="op">=</span> X.corrwith(y)</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Standardized regression coefficients</span></span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>lr <span class="op">=</span> LinearRegression().fit(X_scaled, y)</span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>std_coef <span class="op">=</span> pd.Series(lr.coef_, index<span class="op">=</span>X.columns)</span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Usefulness (R² drop)</span></span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a>baseline_r2 <span class="op">=</span> r2_score(y, lr.predict(X_scaled))</span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a>usefulness <span class="op">=</span> pd.Series({</span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a>    col: baseline_r2 <span class="op">-</span> r2_score(y, LinearRegression().fit(X_scaled.drop(columns<span class="op">=</span>[col]), y).predict(X_scaled.drop(columns<span class="op">=</span>[col])))</span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> col <span class="kw">in</span> X.columns</span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-30"><a href="#cb9-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Johnson's relative weights approximation</span></span>
<span id="cb9-31"><a href="#cb9-31" aria-hidden="true" tabindex="-1"></a>rel_weights <span class="op">=</span> std_coef<span class="op">**</span><span class="dv">2</span> <span class="op">*</span> pearson_corr</span>
<span id="cb9-32"><a href="#cb9-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-33"><a href="#cb9-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Random Forest Gini importance</span></span>
<span id="cb9-34"><a href="#cb9-34" aria-hidden="true" tabindex="-1"></a>rf <span class="op">=</span> RandomForestRegressor(random_state<span class="op">=</span><span class="dv">42</span>).fit(X, y)</span>
<span id="cb9-35"><a href="#cb9-35" aria-hidden="true" tabindex="-1"></a>gini_importance <span class="op">=</span> pd.Series(rf.feature_importances_, index<span class="op">=</span>X.columns)</span>
<span id="cb9-36"><a href="#cb9-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-37"><a href="#cb9-37" aria-hidden="true" tabindex="-1"></a><span class="co"># XGBoost importance</span></span>
<span id="cb9-38"><a href="#cb9-38" aria-hidden="true" tabindex="-1"></a>xgb <span class="op">=</span> XGBRegressor(random_state<span class="op">=</span><span class="dv">42</span>).fit(X, y)</span>
<span id="cb9-39"><a href="#cb9-39" aria-hidden="true" tabindex="-1"></a>xgb_importance <span class="op">=</span> pd.Series(xgb.feature_importances_, index<span class="op">=</span>X.columns)</span>
<span id="cb9-40"><a href="#cb9-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-41"><a href="#cb9-41" aria-hidden="true" tabindex="-1"></a><span class="co"># Assemble results</span></span>
<span id="cb9-42"><a href="#cb9-42" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> pd.DataFrame({</span>
<span id="cb9-43"><a href="#cb9-43" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Pearson"</span>: pearson_corr,</span>
<span id="cb9-44"><a href="#cb9-44" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Std Coef"</span>: std_coef,</span>
<span id="cb9-45"><a href="#cb9-45" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Usefulness (ΔR²)"</span>: usefulness,</span>
<span id="cb9-46"><a href="#cb9-46" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Rel Weights"</span>: rel_weights,</span>
<span id="cb9-47"><a href="#cb9-47" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Gini Importance"</span>: gini_importance,</span>
<span id="cb9-48"><a href="#cb9-48" aria-hidden="true" tabindex="-1"></a>    <span class="st">"XGBoost"</span>: xgb_importance</span>
<span id="cb9-49"><a href="#cb9-49" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb9-50"><a href="#cb9-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-51"><a href="#cb9-51" aria-hidden="true" tabindex="-1"></a><span class="co"># Format results to percentage scale and rank</span></span>
<span id="cb9-52"><a href="#cb9-52" aria-hidden="true" tabindex="-1"></a>formatted_results <span class="op">=</span> (results <span class="op">*</span> <span class="dv">100</span>).<span class="bu">round</span>(<span class="dv">1</span>)</span>
<span id="cb9-53"><a href="#cb9-53" aria-hidden="true" tabindex="-1"></a>formatted_results[<span class="st">"Average Rank"</span>] <span class="op">=</span> formatted_results.rank(ascending<span class="op">=</span><span class="va">False</span>).mean(axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb9-54"><a href="#cb9-54" aria-hidden="true" tabindex="-1"></a>formatted_results <span class="op">=</span> formatted_results.sort_values(<span class="st">"Average Rank"</span>)</span>
<span id="cb9-55"><a href="#cb9-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-56"><a href="#cb9-56" aria-hidden="true" tabindex="-1"></a>formatted_results</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="24">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Pearson</th>
<th data-quarto-table-cell-role="th">Std Coef</th>
<th data-quarto-table-cell-role="th">Usefulness (ΔR²)</th>
<th data-quarto-table-cell-role="th">Rel Weights</th>
<th data-quarto-table-cell-role="th">Gini Importance</th>
<th data-quarto-table-cell-role="th">XGBoost</th>
<th data-quarto-table-cell-role="th">Average Rank</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">trust</td>
<td>25.6</td>
<td>13.6</td>
<td>0.8</td>
<td>0.5</td>
<td>15.6</td>
<td>29.0</td>
<td>1.500000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">impact</td>
<td>25.5</td>
<td>15.0</td>
<td>1.1</td>
<td>0.6</td>
<td>14.1</td>
<td>18.5</td>
<td>1.500000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">service</td>
<td>25.1</td>
<td>10.4</td>
<td>0.5</td>
<td>0.3</td>
<td>13.0</td>
<td>11.1</td>
<td>3.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">easy</td>
<td>21.3</td>
<td>2.6</td>
<td>0.0</td>
<td>0.0</td>
<td>10.0</td>
<td>7.1</td>
<td>6.000000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">appealing</td>
<td>20.8</td>
<td>4.0</td>
<td>0.1</td>
<td>0.0</td>
<td>8.6</td>
<td>6.6</td>
<td>6.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">build</td>
<td>19.2</td>
<td>2.3</td>
<td>0.0</td>
<td>0.0</td>
<td>10.2</td>
<td>7.9</td>
<td>6.000000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">differs</td>
<td>18.5</td>
<td>3.3</td>
<td>0.1</td>
<td>0.0</td>
<td>9.0</td>
<td>5.6</td>
<td>6.833333</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">rewarding</td>
<td>19.5</td>
<td>0.6</td>
<td>0.0</td>
<td>0.0</td>
<td>10.1</td>
<td>6.5</td>
<td>7.000000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">popular</td>
<td>17.1</td>
<td>1.9</td>
<td>0.0</td>
<td>0.0</td>
<td>9.5</td>
<td>7.6</td>
<td>7.166667</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<section id="summary-of-key-driver-rankings" class="level3">
<h3 class="anchored" data-anchor-id="summary-of-key-driver-rankings">Summary of Key Driver Rankings</h3>
<p>The integrated importance table, incorporating six metrics including XGBoost, reveals consistent patterns in identifying the most influential predictors of satisfaction. Two variables—<strong>trust</strong> and <strong>impact</strong>—consistently rank at the top across all metrics, achieving the lowest average rank of 1.5. These results suggest that customers’ trust in the brand and the perceived impact of the brand are the strongest drivers of satisfaction.</p>
<p><strong>Service</strong> emerges as the third most important predictor, also scoring highly across linear and tree-based methods. This reinforces the importance of customer service in shaping satisfaction outcomes.</p>
<p>In contrast, variables such as <strong>popular</strong>, <strong>rewarding</strong>, and <strong>differs</strong> exhibit low importance across all metrics. Their limited explanatory power suggests they contribute marginally, if at all, to variations in satisfaction in this sample.</p>
<p>Interestingly, while some predictors (e.g., <strong>easy</strong>, <strong>appealing</strong>) show moderate linear correlations, their standardized coefficients and machine learning-based importances (e.g., Gini, XGBoost) remain relatively low, indicating possible redundancy or shared variance with stronger predictors.</p>
<p>In summary, the combined analysis across six evaluation methods supports the conclusion that <strong>trust</strong>, <strong>impact</strong>, and <strong>service</strong> are the most robust and consistently influential drivers of customer satisfaction.</p>


<!-- -->

</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb10" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Identifying Key Drivers of Customer Satisfaction: A Comparative Modeling Approach"</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span><span class="co"> "Kehang Qin"</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> today</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a><span class="fu">## A</span></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a><span class="fu">## 1a. K-Means</span></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>_todo: write your own code to implement the k-means algorithm.  Make plots of the various steps the algorithm takes so you can "see" the algorithm working.  Test your algorithm on the Palmer Penguins dataset, specifically using the bill length and flipper length variables.  Compare your results to the built-in `kmeans` function in R or Python._</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>_todo: Calculate both the within-cluster-sum-of-squares and silhouette scores (you can use built-in functions to do so) and plot the results for various numbers of clusters (ie, K=2,3,...,7). What is the "right" number of clusters as suggested by these two metrics?_</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>_If you want a challenge, add your plots as an animated gif on your website so that the result looks something like [this](https://www.youtube.com/shorts/XCsoWZU9oN8)._</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a><span class="fu">## 2a. K Nearest Neighbors</span></span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>_todo: use the following code (or the python equivalent) to generate a synthetic dataset for the k-nearest neighbors algorithm.  The code generates a dataset with two features, `x1` and `x2`, and a binary outcome variable `y` that is determined by whether `x2` is above or below a wiggly boundary defined by a sin function._</span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true" tabindex="-1"></a>x1 <span class="op">=</span> np.random.uniform(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, n)</span>
<span id="cb10-32"><a href="#cb10-32" aria-hidden="true" tabindex="-1"></a>x2 <span class="op">=</span> np.random.uniform(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, n)</span>
<span id="cb10-33"><a href="#cb10-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-34"><a href="#cb10-34" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.column_stack((x1, x2)) </span>
<span id="cb10-35"><a href="#cb10-35" aria-hidden="true" tabindex="-1"></a>boundary <span class="op">=</span> np.sin(<span class="dv">4</span> <span class="op">*</span> x1) <span class="op">+</span> x1</span>
<span id="cb10-36"><a href="#cb10-36" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> np.where(x2 <span class="op">&gt;</span> boundary, <span class="dv">1</span>, <span class="dv">0</span>).astype(<span class="bu">str</span>)</span>
<span id="cb10-37"><a href="#cb10-37" aria-hidden="true" tabindex="-1"></a>dat <span class="op">=</span> pd.DataFrame({<span class="st">'x1'</span>: x1, <span class="st">'x2'</span>: x2, <span class="st">'y'</span>: y})</span>
<span id="cb10-38"><a href="#cb10-38" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb10-39"><a href="#cb10-39" aria-hidden="true" tabindex="-1"></a>::::</span>
<span id="cb10-40"><a href="#cb10-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-41"><a href="#cb10-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-42"><a href="#cb10-42" aria-hidden="true" tabindex="-1"></a>_todo: plot the data where the horizontal axis is `x1`, the vertical axis is `x2`, and the points are colored by the value of `y`.  You may optionally draw the wiggly boundary._</span>
<span id="cb10-43"><a href="#cb10-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-44"><a href="#cb10-44" aria-hidden="true" tabindex="-1"></a>_todo: generate a test dataset with 100 points, using the same code as above but with a different seed._</span>
<span id="cb10-45"><a href="#cb10-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-46"><a href="#cb10-46" aria-hidden="true" tabindex="-1"></a>_todo: implement KNN by hand.  Check you work with a built-in function -- eg, `class::knn()` or `caret::train(method="knn")` in R, or scikit-learn's `KNeighborsClassifier` in Python._</span>
<span id="cb10-47"><a href="#cb10-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-48"><a href="#cb10-48" aria-hidden="true" tabindex="-1"></a>_todo: run your function for k=1,...,k=30, each time noting the percentage of correctly-classified points from the test dataset. Plot the results, where the horizontal axis is 1-30 and the vertical axis is the percentage of correctly-classified points. What is the optimal value of k as suggested by your plot?_ </span>
<span id="cb10-49"><a href="#cb10-49" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb10-50"><a href="#cb10-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-51"><a href="#cb10-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-52"><a href="#cb10-52" aria-hidden="true" tabindex="-1"></a><span class="fu">## 1b. Latent-Class MNL</span></span>
<span id="cb10-53"><a href="#cb10-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-54"><a href="#cb10-54" aria-hidden="true" tabindex="-1"></a><span class="fu">### Reshape yogurt data from wide to long format</span></span>
<span id="cb10-55"><a href="#cb10-55" aria-hidden="true" tabindex="-1"></a>The original yogurt dataset was provided in a wide format, where each row represented one consumer and contained multiple product-related variables. To facilitate multinomial logit modeling, the data were transformed into long format. In the reshaped structure, each row corresponds to one product alternative per consumer, with associated attributes including price, featured status, and a binary choice indicator.</span>
<span id="cb10-56"><a href="#cb10-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-59"><a href="#cb10-59" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb10-60"><a href="#cb10-60" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb10-61"><a href="#cb10-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-62"><a href="#cb10-62" aria-hidden="true" tabindex="-1"></a><span class="co"># Load yogurt dataset and reshape it from wide to long format</span></span>
<span id="cb10-63"><a href="#cb10-63" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb10-64"><a href="#cb10-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-65"><a href="#cb10-65" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the data</span></span>
<span id="cb10-66"><a href="#cb10-66" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">"yogurt_data.csv"</span>)</span>
<span id="cb10-67"><a href="#cb10-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-68"><a href="#cb10-68" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert wide format to long format suitable for MNL estimation</span></span>
<span id="cb10-69"><a href="#cb10-69" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> reshape_yogurt_data(df):</span>
<span id="cb10-70"><a href="#cb10-70" aria-hidden="true" tabindex="-1"></a>    records <span class="op">=</span> []</span>
<span id="cb10-71"><a href="#cb10-71" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _, row <span class="kw">in</span> df.iterrows():</span>
<span id="cb10-72"><a href="#cb10-72" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">5</span>):  <span class="co"># Iterate over 4 yogurt options</span></span>
<span id="cb10-73"><a href="#cb10-73" aria-hidden="true" tabindex="-1"></a>            records.append({</span>
<span id="cb10-74"><a href="#cb10-74" aria-hidden="true" tabindex="-1"></a>                <span class="st">"id"</span>: row[<span class="st">"id"</span>],</span>
<span id="cb10-75"><a href="#cb10-75" aria-hidden="true" tabindex="-1"></a>                <span class="st">"alt"</span>: j,</span>
<span id="cb10-76"><a href="#cb10-76" aria-hidden="true" tabindex="-1"></a>                <span class="st">"price"</span>: row[<span class="ss">f"p</span><span class="sc">{</span>j<span class="sc">}</span><span class="ss">"</span>],</span>
<span id="cb10-77"><a href="#cb10-77" aria-hidden="true" tabindex="-1"></a>                <span class="st">"featured"</span>: row[<span class="ss">f"f</span><span class="sc">{</span>j<span class="sc">}</span><span class="ss">"</span>],</span>
<span id="cb10-78"><a href="#cb10-78" aria-hidden="true" tabindex="-1"></a>                <span class="st">"choice"</span>: <span class="dv">1</span> <span class="cf">if</span> row[<span class="ss">f"y</span><span class="sc">{</span>j<span class="sc">}</span><span class="ss">"</span>] <span class="op">==</span> <span class="dv">1</span> <span class="cf">else</span> <span class="dv">0</span></span>
<span id="cb10-79"><a href="#cb10-79" aria-hidden="true" tabindex="-1"></a>            })</span>
<span id="cb10-80"><a href="#cb10-80" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> pd.DataFrame(records)</span>
<span id="cb10-81"><a href="#cb10-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-82"><a href="#cb10-82" aria-hidden="true" tabindex="-1"></a>long_df <span class="op">=</span> reshape_yogurt_data(df)</span>
<span id="cb10-83"><a href="#cb10-83" aria-hidden="true" tabindex="-1"></a>long_df.head()</span>
<span id="cb10-84"><a href="#cb10-84" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb10-85"><a href="#cb10-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-86"><a href="#cb10-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-87"><a href="#cb10-87" aria-hidden="true" tabindex="-1"></a><span class="fu">### Fit standard MNL and latent-class MNL (for K=2 to 5)</span></span>
<span id="cb10-88"><a href="#cb10-88" aria-hidden="true" tabindex="-1"></a>A standard Multinomial Logit (MNL) model was estimated using the long-format data. The model includes price, featured advertising status, and alternative-specific intercepts as predictors. Coefficients were estimated using maximum likelihood via logistic regression. As expected, price exerts a negative influence on choice probability, while featured advertising has a positive effect.</span>
<span id="cb10-89"><a href="#cb10-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-90"><a href="#cb10-90" aria-hidden="true" tabindex="-1"></a>To account for preference heterogeneity, latent-class MNL models were approximated by fitting Gaussian Mixture Models (GMMs) to the product-level covariates (price and featured). Probabilistic segment assignments were obtained for each observation across model specifications with 2 to 5 latent classes. The log-likelihood of each fitted GMM was recorded for model comparison.</span>
<span id="cb10-91"><a href="#cb10-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-94"><a href="#cb10-94" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb10-95"><a href="#cb10-95" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb10-96"><a href="#cb10-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-97"><a href="#cb10-97" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit standard multinomial logit and latent-class MNLs (K=2,3,4,5)</span></span>
<span id="cb10-98"><a href="#cb10-98" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.formula.api <span class="im">as</span> smf</span>
<span id="cb10-99"><a href="#cb10-99" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.mixture <span class="im">import</span> GaussianMixture</span>
<span id="cb10-100"><a href="#cb10-100" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb10-101"><a href="#cb10-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-102"><a href="#cb10-102" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit standard MNL using statsmodels (with alternative-specific intercepts)</span></span>
<span id="cb10-103"><a href="#cb10-103" aria-hidden="true" tabindex="-1"></a>long_df[<span class="st">"alt_2"</span>] <span class="op">=</span> (long_df[<span class="st">"alt"</span>] <span class="op">==</span> <span class="dv">2</span>).astype(<span class="bu">int</span>)</span>
<span id="cb10-104"><a href="#cb10-104" aria-hidden="true" tabindex="-1"></a>long_df[<span class="st">"alt_3"</span>] <span class="op">=</span> (long_df[<span class="st">"alt"</span>] <span class="op">==</span> <span class="dv">3</span>).astype(<span class="bu">int</span>)</span>
<span id="cb10-105"><a href="#cb10-105" aria-hidden="true" tabindex="-1"></a>long_df[<span class="st">"alt_4"</span>] <span class="op">=</span> (long_df[<span class="st">"alt"</span>] <span class="op">==</span> <span class="dv">4</span>).astype(<span class="bu">int</span>)</span>
<span id="cb10-106"><a href="#cb10-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-107"><a href="#cb10-107" aria-hidden="true" tabindex="-1"></a>mnl_model <span class="op">=</span> smf.logit(<span class="st">"choice ~ price + featured + alt_2 + alt_3 + alt_4"</span>, data<span class="op">=</span>long_df).fit()</span>
<span id="cb10-108"><a href="#cb10-108" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mnl_model.summary())</span>
<span id="cb10-109"><a href="#cb10-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-110"><a href="#cb10-110" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit latent-class MNL using GMM clustering as proxy for soft segment assignment</span></span>
<span id="cb10-111"><a href="#cb10-111" aria-hidden="true" tabindex="-1"></a>X_cluster <span class="op">=</span> long_df[[<span class="st">"price"</span>, <span class="st">"featured"</span>]]</span>
<span id="cb10-112"><a href="#cb10-112" aria-hidden="true" tabindex="-1"></a>log_likelihoods <span class="op">=</span> []</span>
<span id="cb10-113"><a href="#cb10-113" aria-hidden="true" tabindex="-1"></a>class_probs <span class="op">=</span> {}</span>
<span id="cb10-114"><a href="#cb10-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-115"><a href="#cb10-115" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2</span>, <span class="dv">6</span>):  <span class="co"># For K = 2, 3, 4, 5</span></span>
<span id="cb10-116"><a href="#cb10-116" aria-hidden="true" tabindex="-1"></a>    gmm <span class="op">=</span> GaussianMixture(n_components<span class="op">=</span>k, random_state<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb10-117"><a href="#cb10-117" aria-hidden="true" tabindex="-1"></a>    gmm.fit(X_cluster)</span>
<span id="cb10-118"><a href="#cb10-118" aria-hidden="true" tabindex="-1"></a>    class_probs[k] <span class="op">=</span> gmm.predict_proba(X_cluster)</span>
<span id="cb10-119"><a href="#cb10-119" aria-hidden="true" tabindex="-1"></a>    log_likelihoods.append(gmm.lower_bound_ <span class="op">*</span> <span class="bu">len</span>(X_cluster))  <span class="co"># Approximate total log-likelihood</span></span>
<span id="cb10-120"><a href="#cb10-120" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb10-121"><a href="#cb10-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-122"><a href="#cb10-122" aria-hidden="true" tabindex="-1"></a><span class="fu">### Calculate BIC and determine the best number of classes</span></span>
<span id="cb10-123"><a href="#cb10-123" aria-hidden="true" tabindex="-1"></a>Model fit was evaluated using the Bayesian Information Criterion (BIC), computed as:</span>
<span id="cb10-124"><a href="#cb10-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-125"><a href="#cb10-125" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb10-126"><a href="#cb10-126" aria-hidden="true" tabindex="-1"></a>BIC = -2 \cdot \ell_n + k \cdot \log(n)</span>
<span id="cb10-127"><a href="#cb10-127" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb10-128"><a href="#cb10-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-129"><a href="#cb10-129" aria-hidden="true" tabindex="-1"></a>where <span class="sc">\(</span> \ell_n <span class="sc">\)</span> is the log-likelihood of the model, <span class="sc">\(</span> k <span class="sc">\)</span> is the number of estimated parameters, and <span class="sc">\(</span> n <span class="sc">\)</span> is the sample size. A lower BIC indicates a more favorable balance between model complexity and fit. BIC values were calculated for models with 2 through 5 latent classes.</span>
<span id="cb10-130"><a href="#cb10-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-131"><a href="#cb10-131" aria-hidden="true" tabindex="-1"></a>The BIC curve indicates that the model with **K = 5** latent classes achieves the lowest BIC value, suggesting it is the most appropriate specification among those considered.</span>
<span id="cb10-132"><a href="#cb10-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-135"><a href="#cb10-135" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb10-136"><a href="#cb10-136" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb10-137"><a href="#cb10-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-138"><a href="#cb10-138" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute BIC values for each latent class model and select the best K</span></span>
<span id="cb10-139"><a href="#cb10-139" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb10-140"><a href="#cb10-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-141"><a href="#cb10-141" aria-hidden="true" tabindex="-1"></a>n_obs <span class="op">=</span> <span class="bu">len</span>(X_cluster)</span>
<span id="cb10-142"><a href="#cb10-142" aria-hidden="true" tabindex="-1"></a>bic_scores <span class="op">=</span> []</span>
<span id="cb10-143"><a href="#cb10-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-144"><a href="#cb10-144" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k, logL <span class="kw">in</span> <span class="bu">zip</span>(<span class="bu">range</span>(<span class="dv">2</span>, <span class="dv">6</span>), log_likelihoods):</span>
<span id="cb10-145"><a href="#cb10-145" aria-hidden="true" tabindex="-1"></a>    n_params <span class="op">=</span> k <span class="op">*</span> <span class="dv">3</span>  <span class="co"># Assume 3 parameters (intercept, price, featured) per class</span></span>
<span id="cb10-146"><a href="#cb10-146" aria-hidden="true" tabindex="-1"></a>    bic <span class="op">=</span> <span class="op">-</span><span class="dv">2</span> <span class="op">*</span> logL <span class="op">+</span> n_params <span class="op">*</span> np.log(n_obs)</span>
<span id="cb10-147"><a href="#cb10-147" aria-hidden="true" tabindex="-1"></a>    bic_scores.append(bic)</span>
<span id="cb10-148"><a href="#cb10-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-149"><a href="#cb10-149" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot BIC vs number of latent classes</span></span>
<span id="cb10-150"><a href="#cb10-150" aria-hidden="true" tabindex="-1"></a>plt.plot(<span class="bu">range</span>(<span class="dv">2</span>, <span class="dv">6</span>), bic_scores, marker<span class="op">=</span><span class="st">'o'</span>)</span>
<span id="cb10-151"><a href="#cb10-151" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Number of latent classes (K)"</span>)</span>
<span id="cb10-152"><a href="#cb10-152" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"BIC"</span>)</span>
<span id="cb10-153"><a href="#cb10-153" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Model Selection by BIC"</span>)</span>
<span id="cb10-154"><a href="#cb10-154" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb10-155"><a href="#cb10-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-156"><a href="#cb10-156" aria-hidden="true" tabindex="-1"></a>best_k <span class="op">=</span> np.argmin(bic_scores) <span class="op">+</span> <span class="dv">2</span></span>
<span id="cb10-157"><a href="#cb10-157" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Best number of classes suggested by BIC: K = </span><span class="sc">{</span>best_k<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb10-158"><a href="#cb10-158" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb10-159"><a href="#cb10-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-160"><a href="#cb10-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-161"><a href="#cb10-161" aria-hidden="true" tabindex="-1"></a><span class="fu">### Compare aggregate MNL vs. latent-class parameter estimates</span></span>
<span id="cb10-162"><a href="#cb10-162" aria-hidden="true" tabindex="-1"></a>To investigate heterogeneity in price sensitivity, the estimated price coefficient from the aggregate MNL model was compared to the class-weighted average prices implied by the latent-class models. The standard MNL yielded a price coefficient of approximately **-31.98**, consistent with strong price aversion at the population level.</span>
<span id="cb10-163"><a href="#cb10-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-164"><a href="#cb10-164" aria-hidden="true" tabindex="-1"></a>For each latent-class model (K = 2 to 5), the class 1 segment's weighted average price was computed. As the number of segments increased, variation in average price levels became more apparent, indicating distinct behavioral patterns across latent classes. These findings highlight the advantage of latent-class MNL in capturing preference heterogeneity that may be obscured in aggregate models.</span>
<span id="cb10-165"><a href="#cb10-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-166"><a href="#cb10-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-169"><a href="#cb10-169" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb10-170"><a href="#cb10-170" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb10-171"><a href="#cb10-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-172"><a href="#cb10-172" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare price estimates from aggregate MNL and latent-class segmentation</span></span>
<span id="cb10-173"><a href="#cb10-173" aria-hidden="true" tabindex="-1"></a><span class="co"># Use class-weighted average price as an intuitive summary</span></span>
<span id="cb10-174"><a href="#cb10-174" aria-hidden="true" tabindex="-1"></a>agg_coef <span class="op">=</span> mnl_model.params[<span class="st">"price"</span>]</span>
<span id="cb10-175"><a href="#cb10-175" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Aggregate MNL price coefficient: </span><span class="sc">{</span>agg_coef<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb10-176"><a href="#cb10-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-177"><a href="#cb10-177" aria-hidden="true" tabindex="-1"></a><span class="co"># For each K, compute weighted average price across segments</span></span>
<span id="cb10-178"><a href="#cb10-178" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> [<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>]:</span>
<span id="cb10-179"><a href="#cb10-179" aria-hidden="true" tabindex="-1"></a>    weights <span class="op">=</span> class_probs[k]</span>
<span id="cb10-180"><a href="#cb10-180" aria-hidden="true" tabindex="-1"></a>    weighted_avg_price <span class="op">=</span> np.average(long_df[<span class="st">"price"</span>], weights<span class="op">=</span>weights[:, <span class="dv">0</span>])  <span class="co"># just for first segment</span></span>
<span id="cb10-181"><a href="#cb10-181" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"K=</span><span class="sc">{</span>k<span class="sc">}</span><span class="ss"> - Weighted avg price (segment 1): </span><span class="sc">{</span>weighted_avg_price<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb10-182"><a href="#cb10-182" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb10-183"><a href="#cb10-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-184"><a href="#cb10-184" aria-hidden="true" tabindex="-1"></a><span class="fu">### Conclusion</span></span>
<span id="cb10-185"><a href="#cb10-185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-186"><a href="#cb10-186" aria-hidden="true" tabindex="-1"></a>The latent-class multinomial logit model provides a flexible framework for modeling unobserved consumer heterogeneity. By segmenting the market into latent classes, the model captures variation in preference structures that are not identifiable through aggregate analysis. The five-segment specification was found to provide the best fit according to BIC, and revealed meaningful differences in price sensitivity across segments. This approach offers enhanced insight into consumer choice behavior and may support more targeted pricing and promotional strategies.</span>
<span id="cb10-187"><a href="#cb10-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-188"><a href="#cb10-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-189"><a href="#cb10-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-190"><a href="#cb10-190" aria-hidden="true" tabindex="-1"></a><span class="fu">## 2b. Key Drivers Analysis</span></span>
<span id="cb10-191"><a href="#cb10-191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-192"><a href="#cb10-192" aria-hidden="true" tabindex="-1"></a>This section replicates the variable importance summary presented in slide 75 of the Session 5 lecture slides. The goal is to identify key predictors of <span class="in">`satisfaction`</span> using a variety of variable importance metrics. The dataset <span class="in">`data_for_drivers_analysis.csv`</span> contains ten predictors, and the following five methods were used to evaluate their relative influence:</span>
<span id="cb10-193"><a href="#cb10-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-194"><a href="#cb10-194" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Pearson correlations** between each predictor and satisfaction.</span>
<span id="cb10-195"><a href="#cb10-195" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Standardized regression coefficients** from a linear model with standardized predictors.</span>
<span id="cb10-196"><a href="#cb10-196" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Usefulness**, measured as the reduction in out-of-sample <span class="sc">\(</span> R^2 <span class="sc">\)</span> when a variable is excluded from the model.</span>
<span id="cb10-197"><a href="#cb10-197" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Johnson’s relative weights**, approximated by the squared standardized coefficients weighted by correlation.</span>
<span id="cb10-198"><a href="#cb10-198" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Mean decrease in Gini**, computed from a Random Forest model.</span>
<span id="cb10-199"><a href="#cb10-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-200"><a href="#cb10-200" aria-hidden="true" tabindex="-1"></a>All metrics are scaled to percentages and sorted by average rank across methods to facilitate comparison.</span>
<span id="cb10-201"><a href="#cb10-201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-202"><a href="#cb10-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-205"><a href="#cb10-205" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb10-206"><a href="#cb10-206" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb10-207"><a href="#cb10-207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-208"><a href="#cb10-208" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> xgboost <span class="im">import</span> XGBRegressor</span>
<span id="cb10-209"><a href="#cb10-209" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb10-210"><a href="#cb10-210" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb10-211"><a href="#cb10-211" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestRegressor</span>
<span id="cb10-212"><a href="#cb10-212" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> r2_score</span>
<span id="cb10-213"><a href="#cb10-213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-214"><a href="#cb10-214" aria-hidden="true" tabindex="-1"></a><span class="co"># Load data</span></span>
<span id="cb10-215"><a href="#cb10-215" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">"data_for_drivers_analysis.csv"</span>)</span>
<span id="cb10-216"><a href="#cb10-216" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df.drop(columns<span class="op">=</span>[<span class="st">"brand"</span>, <span class="st">"id"</span>, <span class="st">"satisfaction"</span>])</span>
<span id="cb10-217"><a href="#cb10-217" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df[<span class="st">"satisfaction"</span>]</span>
<span id="cb10-218"><a href="#cb10-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-219"><a href="#cb10-219" aria-hidden="true" tabindex="-1"></a><span class="co"># Standardize predictors</span></span>
<span id="cb10-220"><a href="#cb10-220" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb10-221"><a href="#cb10-221" aria-hidden="true" tabindex="-1"></a>X_scaled <span class="op">=</span> pd.DataFrame(scaler.fit_transform(X), columns<span class="op">=</span>X.columns)</span>
<span id="cb10-222"><a href="#cb10-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-223"><a href="#cb10-223" aria-hidden="true" tabindex="-1"></a><span class="co"># Pearson correlations</span></span>
<span id="cb10-224"><a href="#cb10-224" aria-hidden="true" tabindex="-1"></a>pearson_corr <span class="op">=</span> X.corrwith(y)</span>
<span id="cb10-225"><a href="#cb10-225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-226"><a href="#cb10-226" aria-hidden="true" tabindex="-1"></a><span class="co"># Standardized regression coefficients</span></span>
<span id="cb10-227"><a href="#cb10-227" aria-hidden="true" tabindex="-1"></a>lr <span class="op">=</span> LinearRegression().fit(X_scaled, y)</span>
<span id="cb10-228"><a href="#cb10-228" aria-hidden="true" tabindex="-1"></a>std_coef <span class="op">=</span> pd.Series(lr.coef_, index<span class="op">=</span>X.columns)</span>
<span id="cb10-229"><a href="#cb10-229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-230"><a href="#cb10-230" aria-hidden="true" tabindex="-1"></a><span class="co"># Usefulness (R² drop)</span></span>
<span id="cb10-231"><a href="#cb10-231" aria-hidden="true" tabindex="-1"></a>baseline_r2 <span class="op">=</span> r2_score(y, lr.predict(X_scaled))</span>
<span id="cb10-232"><a href="#cb10-232" aria-hidden="true" tabindex="-1"></a>usefulness <span class="op">=</span> pd.Series({</span>
<span id="cb10-233"><a href="#cb10-233" aria-hidden="true" tabindex="-1"></a>    col: baseline_r2 <span class="op">-</span> r2_score(y, LinearRegression().fit(X_scaled.drop(columns<span class="op">=</span>[col]), y).predict(X_scaled.drop(columns<span class="op">=</span>[col])))</span>
<span id="cb10-234"><a href="#cb10-234" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> col <span class="kw">in</span> X.columns</span>
<span id="cb10-235"><a href="#cb10-235" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb10-236"><a href="#cb10-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-237"><a href="#cb10-237" aria-hidden="true" tabindex="-1"></a><span class="co"># Johnson's relative weights approximation</span></span>
<span id="cb10-238"><a href="#cb10-238" aria-hidden="true" tabindex="-1"></a>rel_weights <span class="op">=</span> std_coef<span class="op">**</span><span class="dv">2</span> <span class="op">*</span> pearson_corr</span>
<span id="cb10-239"><a href="#cb10-239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-240"><a href="#cb10-240" aria-hidden="true" tabindex="-1"></a><span class="co"># Random Forest Gini importance</span></span>
<span id="cb10-241"><a href="#cb10-241" aria-hidden="true" tabindex="-1"></a>rf <span class="op">=</span> RandomForestRegressor(random_state<span class="op">=</span><span class="dv">42</span>).fit(X, y)</span>
<span id="cb10-242"><a href="#cb10-242" aria-hidden="true" tabindex="-1"></a>gini_importance <span class="op">=</span> pd.Series(rf.feature_importances_, index<span class="op">=</span>X.columns)</span>
<span id="cb10-243"><a href="#cb10-243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-244"><a href="#cb10-244" aria-hidden="true" tabindex="-1"></a><span class="co"># XGBoost importance</span></span>
<span id="cb10-245"><a href="#cb10-245" aria-hidden="true" tabindex="-1"></a>xgb <span class="op">=</span> XGBRegressor(random_state<span class="op">=</span><span class="dv">42</span>).fit(X, y)</span>
<span id="cb10-246"><a href="#cb10-246" aria-hidden="true" tabindex="-1"></a>xgb_importance <span class="op">=</span> pd.Series(xgb.feature_importances_, index<span class="op">=</span>X.columns)</span>
<span id="cb10-247"><a href="#cb10-247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-248"><a href="#cb10-248" aria-hidden="true" tabindex="-1"></a><span class="co"># Assemble results</span></span>
<span id="cb10-249"><a href="#cb10-249" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> pd.DataFrame({</span>
<span id="cb10-250"><a href="#cb10-250" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Pearson"</span>: pearson_corr,</span>
<span id="cb10-251"><a href="#cb10-251" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Std Coef"</span>: std_coef,</span>
<span id="cb10-252"><a href="#cb10-252" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Usefulness (ΔR²)"</span>: usefulness,</span>
<span id="cb10-253"><a href="#cb10-253" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Rel Weights"</span>: rel_weights,</span>
<span id="cb10-254"><a href="#cb10-254" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Gini Importance"</span>: gini_importance,</span>
<span id="cb10-255"><a href="#cb10-255" aria-hidden="true" tabindex="-1"></a>    <span class="st">"XGBoost"</span>: xgb_importance</span>
<span id="cb10-256"><a href="#cb10-256" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb10-257"><a href="#cb10-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-258"><a href="#cb10-258" aria-hidden="true" tabindex="-1"></a><span class="co"># Format results to percentage scale and rank</span></span>
<span id="cb10-259"><a href="#cb10-259" aria-hidden="true" tabindex="-1"></a>formatted_results <span class="op">=</span> (results <span class="op">*</span> <span class="dv">100</span>).<span class="bu">round</span>(<span class="dv">1</span>)</span>
<span id="cb10-260"><a href="#cb10-260" aria-hidden="true" tabindex="-1"></a>formatted_results[<span class="st">"Average Rank"</span>] <span class="op">=</span> formatted_results.rank(ascending<span class="op">=</span><span class="va">False</span>).mean(axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb10-261"><a href="#cb10-261" aria-hidden="true" tabindex="-1"></a>formatted_results <span class="op">=</span> formatted_results.sort_values(<span class="st">"Average Rank"</span>)</span>
<span id="cb10-262"><a href="#cb10-262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-263"><a href="#cb10-263" aria-hidden="true" tabindex="-1"></a>formatted_results</span>
<span id="cb10-264"><a href="#cb10-264" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb10-265"><a href="#cb10-265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-266"><a href="#cb10-266" aria-hidden="true" tabindex="-1"></a><span class="fu">### Summary of Key Driver Rankings</span></span>
<span id="cb10-267"><a href="#cb10-267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-268"><a href="#cb10-268" aria-hidden="true" tabindex="-1"></a>The integrated importance table, incorporating six metrics including XGBoost, reveals consistent patterns in identifying the most influential predictors of satisfaction. Two variables—**trust** and **impact**—consistently rank at the top across all metrics, achieving the lowest average rank of 1.5. These results suggest that customers' trust in the brand and the perceived impact of the brand are the strongest drivers of satisfaction.</span>
<span id="cb10-269"><a href="#cb10-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-270"><a href="#cb10-270" aria-hidden="true" tabindex="-1"></a>**Service** emerges as the third most important predictor, also scoring highly across linear and tree-based methods. This reinforces the importance of customer service in shaping satisfaction outcomes.</span>
<span id="cb10-271"><a href="#cb10-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-272"><a href="#cb10-272" aria-hidden="true" tabindex="-1"></a>In contrast, variables such as **popular**, **rewarding**, and **differs** exhibit low importance across all metrics. Their limited explanatory power suggests they contribute marginally, if at all, to variations in satisfaction in this sample.</span>
<span id="cb10-273"><a href="#cb10-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-274"><a href="#cb10-274" aria-hidden="true" tabindex="-1"></a>Interestingly, while some predictors (e.g., **easy**, **appealing**) show moderate linear correlations, their standardized coefficients and machine learning-based importances (e.g., Gini, XGBoost) remain relatively low, indicating possible redundancy or shared variance with stronger predictors.</span>
<span id="cb10-275"><a href="#cb10-275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-276"><a href="#cb10-276" aria-hidden="true" tabindex="-1"></a>In summary, the combined analysis across six evaluation methods supports the conclusion that **trust**, **impact**, and **service** are the most robust and consistently influential drivers of customer satisfaction.</span>
<span id="cb10-277"><a href="#cb10-277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-278"><a href="#cb10-278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-279"><a href="#cb10-279" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-280"><a href="#cb10-280" aria-hidden="true" tabindex="-1"></a></span>
</code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->




</body></html>