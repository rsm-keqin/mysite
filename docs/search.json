[
  {
    "objectID": "resume/index.html",
    "href": "resume/index.html",
    "title": "Resume",
    "section": "",
    "text": "üìç San Diego, USA | üìû +1 858-281-3806 | ‚úâÔ∏è qinkh1009@gmail.com\n\n\n\nUniversity of California, San Diego\nM.S. in Business Analytics ‚Äì Rady School of Management\nJul 2024 ‚Äì Jun 2025\nUniversity of Melbourne\nB.Com. in Economics\nMar 2021 ‚Äì Feb 2024\nUniversity of Edinburgh (Exchange ‚Äì College of Arts, Humanities, and Social Sciences)\nSep 2023 ‚Äì Dec 2023\n\n\n\n\nYicun Capital Co., Ltd. ‚Äì Project Management Intern\nShanghai | Mar 2024 ‚Äì Jun 2024\n\nConducted preliminary evaluations for potential equity investment projects, assessing financial performance, market prospects, and competitive landscape to determine investment potential.\nProvided data-driven insights and analysis to support management‚Äôs decision-making on whether to proceed with further due diligence.\nConducted in-depth research on key industries, such as the MR hardware sector, tracking technological advancements, market dynamics, and competitive landscape.\n\nAlibaba Consulting ‚Äì Market Research Intern\nRemote | Nov 2022 ‚Äì Feb 2023\n\nConducted data mining and consumer behavior analysis in the retail and pharmaceutical industries to support targeted marketing and user experience optimization.\nApplied SPSS, MATLAB, and linear regression models to forecast pharmaceutical company performance, assisting in strategic planning and decision-making.Delivered data-driven reports on market trends, product performance, and financial evaluations to optimize business and investment strategies.\n\n\n\n\n\nCreative Gaming Marketing Optimization (Feb 2025)\n\nDesigned and executed A/B tests, leveraging data analysis to refine targeting strategies and improve ad performance.\nDeveloped and compared Uplift and Propensity models to predict users‚Äô purchase intent based on advertisement placement, increasing purchase intention rates.\nConducted modeling analysis using Pyrsm with logistic regression, neural networks, random forests, and XGBoost, evaluating model effectiveness through AUC, incremental profit calculation, and other key metrics.\n\nIntuit QuickBooks Upgrade Campaign (Jan 2025)\n\nDeveloped an optimized email marketing strategy using Logistic Regression and Neural Network models, using AUC, ROME, and profitability calculations to predict which businesses are most likely to purchase upgrades in second email campaigns.\nCollaborated with marketing and product teams to refine customer segmentation and targeting, improving precision in customer outreach. Provided data-driven decision support for target group selection, optimizing marketing effectiveness and corporate profitability.\n\nAmazon Video Game Ratings Analysis (Dec 2024)\n\nLed a project analyzing 27 years (1996‚Äì2023) of Amazon customer reviews to predict video game ratings, leveraging data collected by McAuley Lab.\nCleaned and processed raw data, filtering for meaningful features such as price, platform source (Nintendo, PlayStation, Xbox), review text length, and sentiment indicators.\nDeveloped and tested multiple models, including baseline, bias, and linear regression models, to predict user ratings, achieving optimal results with linear regression while minimizing overfitting.\nIdentified key factors influencing customer sentiment and product satisfaction, created a market recommendation report to provide actionable insights for game developers.\n\n\n\n\n\nAWS Industry Research Competition ‚Äì Winner\nApr 2022\n\nLed a 4-member team to complete a comprehensive industry research report within a month, successfully presenting findings in an online pitch and winning the final competition.\nConducted a macro-level analysis of the renewable energy industry, evaluating global policies on carbon neutrality, market demand for lithium-ion batteries, and the overall industry value chain.Analyzed battery cost reduction strategies by comparing CATL and BYD‚Äôs battery designs and supplier strategies.h\n\nJacaranda Stock Association ‚Äì Research Leader\nAug 2022 ‚Äì Dec 2023\n\nOrganized and managed industry research competitions, enhancing team collaboration and presentation skills.\nConducted an in-depth analysis of Federal Reserve interest rate hikes, evaluating their impact on the macroeconomy, financial markets, and commodity prices, and presented findings in weekly meetings.\n\n\n\n\n\n\nTools: Python, SQL, Tableau, R, Excel, SPSS\n\nMethods: A/B Testing, Propensity Modeling, Business Analytics\n\nLanguages: Native Mandarin | Fluent English"
  },
  {
    "objectID": "resume/index.html#education",
    "href": "resume/index.html#education",
    "title": "Resume",
    "section": "",
    "text": "University of California, San Diego\nM.S. in Business Analytics ‚Äì Rady School of Management\nJul 2024 ‚Äì Jun 2025\nUniversity of Melbourne\nB.Com. in Economics\nMar 2021 ‚Äì Feb 2024\nUniversity of Edinburgh (Exchange ‚Äì College of Arts, Humanities, and Social Sciences)\nSep 2023 ‚Äì Dec 2023"
  },
  {
    "objectID": "resume/index.html#work-experience",
    "href": "resume/index.html#work-experience",
    "title": "Resume",
    "section": "",
    "text": "Yicun Capital Co., Ltd. ‚Äì Project Management Intern\nShanghai | Mar 2024 ‚Äì Jun 2024\n\nConducted preliminary evaluations for potential equity investment projects, assessing financial performance, market prospects, and competitive landscape to determine investment potential.\nProvided data-driven insights and analysis to support management‚Äôs decision-making on whether to proceed with further due diligence.\nConducted in-depth research on key industries, such as the MR hardware sector, tracking technological advancements, market dynamics, and competitive landscape.\n\nAlibaba Consulting ‚Äì Market Research Intern\nRemote | Nov 2022 ‚Äì Feb 2023\n\nConducted data mining and consumer behavior analysis in the retail and pharmaceutical industries to support targeted marketing and user experience optimization.\nApplied SPSS, MATLAB, and linear regression models to forecast pharmaceutical company performance, assisting in strategic planning and decision-making.Delivered data-driven reports on market trends, product performance, and financial evaluations to optimize business and investment strategies."
  },
  {
    "objectID": "resume/index.html#projects-leadership",
    "href": "resume/index.html#projects-leadership",
    "title": "Resume",
    "section": "",
    "text": "Creative Gaming Marketing Optimization (Feb 2025)\n\nDesigned and executed A/B tests, leveraging data analysis to refine targeting strategies and improve ad performance.\nDeveloped and compared Uplift and Propensity models to predict users‚Äô purchase intent based on advertisement placement, increasing purchase intention rates.\nConducted modeling analysis using Pyrsm with logistic regression, neural networks, random forests, and XGBoost, evaluating model effectiveness through AUC, incremental profit calculation, and other key metrics.\n\nIntuit QuickBooks Upgrade Campaign (Jan 2025)\n\nDeveloped an optimized email marketing strategy using Logistic Regression and Neural Network models, using AUC, ROME, and profitability calculations to predict which businesses are most likely to purchase upgrades in second email campaigns.\nCollaborated with marketing and product teams to refine customer segmentation and targeting, improving precision in customer outreach. Provided data-driven decision support for target group selection, optimizing marketing effectiveness and corporate profitability.\n\nAmazon Video Game Ratings Analysis (Dec 2024)\n\nLed a project analyzing 27 years (1996‚Äì2023) of Amazon customer reviews to predict video game ratings, leveraging data collected by McAuley Lab.\nCleaned and processed raw data, filtering for meaningful features such as price, platform source (Nintendo, PlayStation, Xbox), review text length, and sentiment indicators.\nDeveloped and tested multiple models, including baseline, bias, and linear regression models, to predict user ratings, achieving optimal results with linear regression while minimizing overfitting.\nIdentified key factors influencing customer sentiment and product satisfaction, created a market recommendation report to provide actionable insights for game developers."
  },
  {
    "objectID": "resume/index.html#research-experience",
    "href": "resume/index.html#research-experience",
    "title": "Resume",
    "section": "",
    "text": "AWS Industry Research Competition ‚Äì Winner\nApr 2022\n\nLed a 4-member team to complete a comprehensive industry research report within a month, successfully presenting findings in an online pitch and winning the final competition.\nConducted a macro-level analysis of the renewable energy industry, evaluating global policies on carbon neutrality, market demand for lithium-ion batteries, and the overall industry value chain.Analyzed battery cost reduction strategies by comparing CATL and BYD‚Äôs battery designs and supplier strategies.h\n\nJacaranda Stock Association ‚Äì Research Leader\nAug 2022 ‚Äì Dec 2023\n\nOrganized and managed industry research competitions, enhancing team collaboration and presentation skills.\nConducted an in-depth analysis of Federal Reserve interest rate hikes, evaluating their impact on the macroeconomy, financial markets, and commodity prices, and presented findings in weekly meetings."
  },
  {
    "objectID": "resume/index.html#skills-certifications",
    "href": "resume/index.html#skills-certifications",
    "title": "Resume",
    "section": "",
    "text": "Tools: Python, SQL, Tableau, R, Excel, SPSS\n\nMethods: A/B Testing, Propensity Modeling, Business Analytics\n\nLanguages: Native Mandarin | Fluent English"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "My Projects",
    "section": "",
    "text": "A Replication of Karlan and List (2007)\n\n\n\n\n\n\nKehang Qin\n\n\nMay 7, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nPoisson Regression Examples\n\n\n\n\n\n\nKehang\n\n\nMay 7, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nProject 1\n\n\n\n\n\n\n\n\n\nApr 21, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/h2_matching/index.html",
    "href": "blog/h2_matching/index.html",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty‚Äôs software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty‚Äôs software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm‚Äôs number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty‚Äôs software. The marketing team would like to use this data to make the claim that firms using Blueprinty‚Äôs software are more successful in getting their patent applications approved.\n\n\n\n\n\n\n\nShow code\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\n\ndf = pd.read_csv(\"blueprinty.csv\")\ndf.head(10)\n\n\n\n\n\n\n\n\n\npatents\nregion\nage\niscustomer\n\n\n\n\n0\n0\nMidwest\n32.5\n0\n\n\n1\n3\nSouthwest\n37.5\n0\n\n\n2\n4\nNorthwest\n27.0\n1\n\n\n3\n3\nNortheast\n24.5\n0\n\n\n4\n3\nSouthwest\n37.0\n0\n\n\n5\n6\nNortheast\n29.5\n1\n\n\n6\n5\nSouthwest\n27.0\n0\n\n\n7\n5\nNortheast\n20.5\n0\n\n\n8\n6\nNortheast\n25.0\n0\n\n\n9\n4\nMidwest\n29.5\n0\n\n\n\n\n\n\n\n\n\n\nTo assess whether Blueprinty customers tend to produce more patents, we examine the distribution and average number of patents awarded over the last five years by customer status.\n\n\nShow code\nsns.histplot(data=df, x=\"patents\", hue=\"iscustomer\", multiple=\"dodge\", palette=\"Set2\", kde=False)\nplt.title(\"Patent Counts by Customer Status\")\nplt.xlabel(\"Number of Patents (last 5 years)\")\nplt.ylabel(\"Firm Count\")\nplt.tight_layout()\nplt.show()\n\n# Mean patents table\nmean_table = df.groupby(\"iscustomer\")[\"patents\"].mean().reset_index()\nmean_table.columns = [\"Customer Status (0 = No, 1 = Yes)\", \"Average Number of Patents\"]\nmean_table\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCustomer Status (0 = No, 1 = Yes)\nAverage Number of Patents\n\n\n\n\n0\n0\n3.473013\n\n\n1\n1\n4.133056\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservation:\nThe histogram reveals that firms using Blueprinty tend to have slightly higher patent productivity. While both customers and non-customers cluster around 2‚Äì5 patents, the customer group has more firms with higher patent counts (e.g., 6+).\nOn average: * Non-customers received approximately 3.47 patents. * Customers received approximately 4.13 patents.\nThis difference, while not conclusive on its own, provides visual and numerical evidence that firms using Blueprinty may be more productive in securing patents. Further analysis (e.g., controlling for region or firm age) is recommended before inferring causality.\n\n\n\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\n\n\n\nWe explore whether Blueprinty customers differ systematically in their firm age or region relative to non-customers. If so, this may confound the relationship between customer status and patent output.\n\n\nShow code\n# Region counts\nregion_table = pd.crosstab(df[\"region\"], df[\"iscustomer\"], normalize=\"index\") * 100\nregion_table.columns = [\"Non-customer (%)\", \"Customer (%)\"]\n\n# Age distribution\nsns.kdeplot(data=df, x=\"age\", hue=\"iscustomer\", common_norm=False, fill=True)\nplt.title(\"Age Distribution by Customer Status\")\nplt.xlabel(\"Firm Age (years)\")\nplt.ylabel(\"Density\")\nplt.tight_layout()\nplt.show()\n\nregion_table.round(1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNon-customer (%)\nCustomer (%)\n\n\nregion\n\n\n\n\n\n\nMidwest\n83.5\n16.5\n\n\nNortheast\n45.4\n54.6\n\n\nNorthwest\n84.5\n15.5\n\n\nSouth\n81.7\n18.3\n\n\nSouthwest\n82.5\n17.5\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservation:\n\nAge: The plot reveals that customers tend to be slightly younger on average than non-customers. This could reflect that newer firms are more likely to adopt modern software like Blueprinty.\nRegion: The table shows differences in customer proportions across regions. Some regions have a higher share of Blueprinty users than others, suggesting region may be a relevant control in further analysis.\n\n\n\n\n\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\n\n\nWe assume that the number of patents ( Y_i ) follows a Poisson distribution:\n\\[\nY_i \\sim \\text{Poisson}(\\lambda)\n\\]\nThe probability mass function is:\n\\[\nf(Y_i \\mid \\lambda) = \\frac{e^{-\\lambda} \\lambda^{Y_i}}{Y_i!}\n\\]\nThe log-likelihood function for ( n ) firms is:\n\\[\n\\log L(\\lambda) = \\sum_{i=1}^{n} \\left( -\\lambda + Y_i \\log \\lambda - \\log(Y_i!) \\right)\n\\]\n\n\n\n\n\nShow code\nfrom scipy.special import gammaln  \nfrom scipy.optimize import minimize_scalar\n\ndef poisson_log_likelihood(lmbda, y):\n    \"\"\"\n    Compute log-likelihood for Poisson(lmbda) given data y\n    \"\"\"\n    return np.sum(-lmbda + y * np.log(lmbda) - gammaln(y + 1))\n\ndf = pd.read_csv(\"blueprinty.csv\")\ny_data = df[\"patents\"].values\n\nprint(\"Log-Likelihood at Œª = 4.0:\", poisson_log_likelihood(4.0, y_data))\n\n\nLog-Likelihood at Œª = 4.0: -3386.8380561598083\n\n\n\n\n\nWe evaluate and visualize the log-likelihood function over a range of Œª values and compare the theoretical MLE (sample mean) with the numerically optimized one.\n\n\nShow code\nfrom scipy.special import gammaln\nfrom scipy.optimize import minimize_scalar\n\ndef poisson_log_likelihood(lmbda, y):\n    return np.sum(-lmbda + y * np.log(lmbda) - gammaln(y + 1))\n\ny_data = df[\"patents\"].values\ny_mean = np.mean(y_data)\n\nlambda_grid = np.linspace(1.0, 7.0, 500)\nloglikelihoods = [poisson_log_likelihood(l, y_data) for l in lambda_grid]\n\nresult = minimize_scalar(lambda l: -poisson_log_likelihood(l, y_data),\n                         bounds=(1.0, 7.0), method=\"bounded\")\nlambda_mle = result.x\n\nplt.figure(figsize=(8, 5))\nplt.plot(lambda_grid, loglikelihoods, color=\"darkorange\", lw=2, label=\"Log-Likelihood\")\nplt.axvline(y_mean, color=\"blue\", ls=\"--\", label=f\"Sample Mean Œª = {y_mean:.2f}\")\nplt.axvline(lambda_mle, color=\"pink\", ls=\":\", label=f\"Numerical MLE Œª = {lambda_mle:.2f}\")\nplt.title(\"Log-Likelihood Curve for Poisson Model\")\nplt.xlabel(\"Œª (Lambda)\")\nplt.ylabel(\"Log-Likelihood\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservation:\n\nThe log-likelihood curve reaches its peak near Œª = 3.68, found via numerical optimization.\nThe sample mean of the patent count is ŒªÃÑ = 3.68, which matches the MLE as expected from Poisson theory.\nBecause the numerical and theoretical Œª are essentially equal, both lines overlap on the plot.\nThis confirms that for Poisson models, the MLE is the sample mean, and validates your estimation function.\n\n\n\n\n\n\n\nTo verify the result mathematically, we take the first derivative of the log-likelihood function:\n\\[\n\\log L(\\lambda) = \\sum_{i=1}^{n} \\left( -\\lambda + Y_i \\log \\lambda - \\log(Y_i!) \\right)\n\\]\nTaking the derivative with respect to ( ) and setting it equal to zero:\n\\[\n\\frac{d}{d\\lambda} \\log L(\\lambda) = \\sum_{i=1}^{n} \\left( -1 + \\frac{Y_i}{\\lambda} \\right) = 0\n\\]\nSolving for ( ):\n\\[\n\\lambda = \\frac{1}{n} \\sum_{i=1}^{n} Y_i = \\bar{Y}\n\\]\nThis confirms that the maximum likelihood estimator (MLE) for ( ) in a Poisson model is the sample mean ( {Y} ), which matches our earlier numerical result.\n\n\n\nWe now use numerical optimization to find the Œª that maximizes the Poisson log-likelihood.\n\n\nShow code\nfrom scipy.optimize import minimize_scalar\n\n# Find Œª that minimizes negative log-likelihood (i.e., maximizes log-likelihood)\nresult = minimize_scalar(\n    lambda l: -poisson_log_likelihood(l, y_data),\n    bounds=(1.0, 7.0),\n    method=\"bounded\"\n)\n\n# Extract results\nlambda_mle = result.x\nloglik_at_mle = -result.fun\n\nprint(f\"Numerical MLE for Œª: {lambda_mle:.4f}\")\nprint(f\"Log-likelihood at MLE: {loglik_at_mle:.2f}\")\n\n\nNumerical MLE for Œª: 3.6847\nLog-likelihood at MLE: -3367.68\n\n\n\n\n\n\n\n\nMLE via Numerical Optimization:\n\nThe numerical MLE for lambda is 3.6847.\n\nThe corresponding log-likelihood value is ‚àí3367.68.\n\nThese values confirm that the MLE aligns with theory: the MLE for a Poisson model equals the sample mean.\n\n\n\n\n\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\n\n\nShow code\nfrom scipy.special import gammaln\n\ndef poisson_loglik(beta, y, X):\n    beta = np.asarray(beta).reshape(-1)\n    linpred = np.clip(X @ beta, -10, 10)\n    lambdas = np.exp(linpred)\n    return -np.sum(-lambdas + y * linpred - gammaln(y + 1))\n\n\n\n\nShow code\nimport statsmodels.api as sm\n\nX = pd.DataFrame({\n    \"intercept\": 1,\n    \"age\": df[\"age\"],\n    \"age2\": df[\"age\"] ** 2,\n    \"iscustomer\": df[\"iscustomer\"]\n})\nX = pd.get_dummies(X.join(df[\"region\"]), columns=[\"region\"], drop_first=True)\nX_mat = X.astype(float).values\ny = df[\"patents\"].astype(float).values \n\n# GLM model\nglm_model = sm.GLM(y, X_mat, family=sm.families.Poisson())\nglm_result = glm_model.fit()\n\nbeta_hat = glm_result.params\nse_hat = glm_result.bse\n\ncoef_table = pd.DataFrame({\n    \"Covariate\": X.columns,\n    \"Œ≤ÃÇ\": np.round(beta_hat, 4),\n    \"Std. Err\": np.round(se_hat, 4)\n})\n\ncoef_table\n\n\n\n\n\n\n\n\n\nCovariate\nŒ≤ÃÇ\nStd. Err\n\n\n\n\n0\nintercept\n-0.5089\n0.1832\n\n\n1\nage\n0.1486\n0.0139\n\n\n2\nage2\n-0.0030\n0.0003\n\n\n3\niscustomer\n0.2076\n0.0309\n\n\n4\nregion_Northeast\n0.0292\n0.0436\n\n\n5\nregion_Northwest\n-0.0176\n0.0538\n\n\n6\nregion_South\n0.0566\n0.0527\n\n\n7\nregion_Southwest\n0.0506\n0.0472\n\n\n\n\n\n\n\n\n\n\n\n\n\nGLM Verification:\nTo validate our custom optimization results, we also fit the same Poisson regression model using Python‚Äôs built-in statsmodels.GLM() function.\nThe results match almost exactly, confirming that our custom likelihood function and optimization procedure are correctly implemented.\n\n\n\n\n\n\n\n\n\nInterpretation of Results:\n\nThe coefficient for iscustomer is positive and statistically significant (0.2076, s.e. 0.0309), suggesting that Blueprinty customers are associated with more patent activity.\nBecause the model is log-linear, the effect of being a customer can be interpreted as:\n( e^{0.2076} ) ‚Üí about 23% more patents on average, holding other variables constant.\nCoefficients on age and age¬≤ indicate a concave effect of firm age on patenting.\n\n\n\n\n\n\nShow code\nX_0 = X.copy(); X_0[\"iscustomer\"] = 0\nX_1 = X.copy(); X_1[\"iscustomer\"] = 1\nX_0_mat = X_0.astype(float).values\nX_1_mat = X_1.astype(float).values\n\ny_pred_0 = np.exp(X_0_mat @ beta_hat)\ny_pred_1 = np.exp(X_1_mat @ beta_hat)\n\ntreatment_effect = np.mean(y_pred_1 - y_pred_0)\nprint(\"Estimated average treatment effect of being a Blueprinty customer:\", round(treatment_effect, 4))\n\n\nEstimated average treatment effect of being a Blueprinty customer: 0.7928\n\n\n\n\n\n\n\n\nCounterfactual Prediction:\nWe use counterfactual prediction to estimate the effect of Blueprinty‚Äôs software.\nBy comparing the predicted number of patents when all firms are treated vs.¬†untreated,\nwe find that the average treatment effect of being a Blueprinty customer is: about 0.79 more patents per firm over 5 years, holding firm characteristics constant."
  },
  {
    "objectID": "blog/h2_matching/index.html#blueprinty-case-study",
    "href": "blog/h2_matching/index.html#blueprinty-case-study",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty‚Äôs software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty‚Äôs software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm‚Äôs number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty‚Äôs software. The marketing team would like to use this data to make the claim that firms using Blueprinty‚Äôs software are more successful in getting their patent applications approved.\n\n\n\n\n\n\n\nShow code\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\n\ndf = pd.read_csv(\"blueprinty.csv\")\ndf.head(10)\n\n\n\n\n\n\n\n\n\npatents\nregion\nage\niscustomer\n\n\n\n\n0\n0\nMidwest\n32.5\n0\n\n\n1\n3\nSouthwest\n37.5\n0\n\n\n2\n4\nNorthwest\n27.0\n1\n\n\n3\n3\nNortheast\n24.5\n0\n\n\n4\n3\nSouthwest\n37.0\n0\n\n\n5\n6\nNortheast\n29.5\n1\n\n\n6\n5\nSouthwest\n27.0\n0\n\n\n7\n5\nNortheast\n20.5\n0\n\n\n8\n6\nNortheast\n25.0\n0\n\n\n9\n4\nMidwest\n29.5\n0\n\n\n\n\n\n\n\n\n\n\nTo assess whether Blueprinty customers tend to produce more patents, we examine the distribution and average number of patents awarded over the last five years by customer status.\n\n\nShow code\nsns.histplot(data=df, x=\"patents\", hue=\"iscustomer\", multiple=\"dodge\", palette=\"Set2\", kde=False)\nplt.title(\"Patent Counts by Customer Status\")\nplt.xlabel(\"Number of Patents (last 5 years)\")\nplt.ylabel(\"Firm Count\")\nplt.tight_layout()\nplt.show()\n\n# Mean patents table\nmean_table = df.groupby(\"iscustomer\")[\"patents\"].mean().reset_index()\nmean_table.columns = [\"Customer Status (0 = No, 1 = Yes)\", \"Average Number of Patents\"]\nmean_table\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCustomer Status (0 = No, 1 = Yes)\nAverage Number of Patents\n\n\n\n\n0\n0\n3.473013\n\n\n1\n1\n4.133056\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservation:\nThe histogram reveals that firms using Blueprinty tend to have slightly higher patent productivity. While both customers and non-customers cluster around 2‚Äì5 patents, the customer group has more firms with higher patent counts (e.g., 6+).\nOn average: * Non-customers received approximately 3.47 patents. * Customers received approximately 4.13 patents.\nThis difference, while not conclusive on its own, provides visual and numerical evidence that firms using Blueprinty may be more productive in securing patents. Further analysis (e.g., controlling for region or firm age) is recommended before inferring causality.\n\n\n\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\n\n\n\nWe explore whether Blueprinty customers differ systematically in their firm age or region relative to non-customers. If so, this may confound the relationship between customer status and patent output.\n\n\nShow code\n# Region counts\nregion_table = pd.crosstab(df[\"region\"], df[\"iscustomer\"], normalize=\"index\") * 100\nregion_table.columns = [\"Non-customer (%)\", \"Customer (%)\"]\n\n# Age distribution\nsns.kdeplot(data=df, x=\"age\", hue=\"iscustomer\", common_norm=False, fill=True)\nplt.title(\"Age Distribution by Customer Status\")\nplt.xlabel(\"Firm Age (years)\")\nplt.ylabel(\"Density\")\nplt.tight_layout()\nplt.show()\n\nregion_table.round(1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNon-customer (%)\nCustomer (%)\n\n\nregion\n\n\n\n\n\n\nMidwest\n83.5\n16.5\n\n\nNortheast\n45.4\n54.6\n\n\nNorthwest\n84.5\n15.5\n\n\nSouth\n81.7\n18.3\n\n\nSouthwest\n82.5\n17.5\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservation:\n\nAge: The plot reveals that customers tend to be slightly younger on average than non-customers. This could reflect that newer firms are more likely to adopt modern software like Blueprinty.\nRegion: The table shows differences in customer proportions across regions. Some regions have a higher share of Blueprinty users than others, suggesting region may be a relevant control in further analysis.\n\n\n\n\n\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\n\n\nWe assume that the number of patents ( Y_i ) follows a Poisson distribution:\n\\[\nY_i \\sim \\text{Poisson}(\\lambda)\n\\]\nThe probability mass function is:\n\\[\nf(Y_i \\mid \\lambda) = \\frac{e^{-\\lambda} \\lambda^{Y_i}}{Y_i!}\n\\]\nThe log-likelihood function for ( n ) firms is:\n\\[\n\\log L(\\lambda) = \\sum_{i=1}^{n} \\left( -\\lambda + Y_i \\log \\lambda - \\log(Y_i!) \\right)\n\\]\n\n\n\n\n\nShow code\nfrom scipy.special import gammaln  \nfrom scipy.optimize import minimize_scalar\n\ndef poisson_log_likelihood(lmbda, y):\n    \"\"\"\n    Compute log-likelihood for Poisson(lmbda) given data y\n    \"\"\"\n    return np.sum(-lmbda + y * np.log(lmbda) - gammaln(y + 1))\n\ndf = pd.read_csv(\"blueprinty.csv\")\ny_data = df[\"patents\"].values\n\nprint(\"Log-Likelihood at Œª = 4.0:\", poisson_log_likelihood(4.0, y_data))\n\n\nLog-Likelihood at Œª = 4.0: -3386.8380561598083\n\n\n\n\n\nWe evaluate and visualize the log-likelihood function over a range of Œª values and compare the theoretical MLE (sample mean) with the numerically optimized one.\n\n\nShow code\nfrom scipy.special import gammaln\nfrom scipy.optimize import minimize_scalar\n\ndef poisson_log_likelihood(lmbda, y):\n    return np.sum(-lmbda + y * np.log(lmbda) - gammaln(y + 1))\n\ny_data = df[\"patents\"].values\ny_mean = np.mean(y_data)\n\nlambda_grid = np.linspace(1.0, 7.0, 500)\nloglikelihoods = [poisson_log_likelihood(l, y_data) for l in lambda_grid]\n\nresult = minimize_scalar(lambda l: -poisson_log_likelihood(l, y_data),\n                         bounds=(1.0, 7.0), method=\"bounded\")\nlambda_mle = result.x\n\nplt.figure(figsize=(8, 5))\nplt.plot(lambda_grid, loglikelihoods, color=\"darkorange\", lw=2, label=\"Log-Likelihood\")\nplt.axvline(y_mean, color=\"blue\", ls=\"--\", label=f\"Sample Mean Œª = {y_mean:.2f}\")\nplt.axvline(lambda_mle, color=\"pink\", ls=\":\", label=f\"Numerical MLE Œª = {lambda_mle:.2f}\")\nplt.title(\"Log-Likelihood Curve for Poisson Model\")\nplt.xlabel(\"Œª (Lambda)\")\nplt.ylabel(\"Log-Likelihood\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservation:\n\nThe log-likelihood curve reaches its peak near Œª = 3.68, found via numerical optimization.\nThe sample mean of the patent count is ŒªÃÑ = 3.68, which matches the MLE as expected from Poisson theory.\nBecause the numerical and theoretical Œª are essentially equal, both lines overlap on the plot.\nThis confirms that for Poisson models, the MLE is the sample mean, and validates your estimation function.\n\n\n\n\n\n\n\nTo verify the result mathematically, we take the first derivative of the log-likelihood function:\n\\[\n\\log L(\\lambda) = \\sum_{i=1}^{n} \\left( -\\lambda + Y_i \\log \\lambda - \\log(Y_i!) \\right)\n\\]\nTaking the derivative with respect to ( ) and setting it equal to zero:\n\\[\n\\frac{d}{d\\lambda} \\log L(\\lambda) = \\sum_{i=1}^{n} \\left( -1 + \\frac{Y_i}{\\lambda} \\right) = 0\n\\]\nSolving for ( ):\n\\[\n\\lambda = \\frac{1}{n} \\sum_{i=1}^{n} Y_i = \\bar{Y}\n\\]\nThis confirms that the maximum likelihood estimator (MLE) for ( ) in a Poisson model is the sample mean ( {Y} ), which matches our earlier numerical result.\n\n\n\nWe now use numerical optimization to find the Œª that maximizes the Poisson log-likelihood.\n\n\nShow code\nfrom scipy.optimize import minimize_scalar\n\n# Find Œª that minimizes negative log-likelihood (i.e., maximizes log-likelihood)\nresult = minimize_scalar(\n    lambda l: -poisson_log_likelihood(l, y_data),\n    bounds=(1.0, 7.0),\n    method=\"bounded\"\n)\n\n# Extract results\nlambda_mle = result.x\nloglik_at_mle = -result.fun\n\nprint(f\"Numerical MLE for Œª: {lambda_mle:.4f}\")\nprint(f\"Log-likelihood at MLE: {loglik_at_mle:.2f}\")\n\n\nNumerical MLE for Œª: 3.6847\nLog-likelihood at MLE: -3367.68\n\n\n\n\n\n\n\n\nMLE via Numerical Optimization:\n\nThe numerical MLE for lambda is 3.6847.\n\nThe corresponding log-likelihood value is ‚àí3367.68.\n\nThese values confirm that the MLE aligns with theory: the MLE for a Poisson model equals the sample mean.\n\n\n\n\n\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\n\n\nShow code\nfrom scipy.special import gammaln\n\ndef poisson_loglik(beta, y, X):\n    beta = np.asarray(beta).reshape(-1)\n    linpred = np.clip(X @ beta, -10, 10)\n    lambdas = np.exp(linpred)\n    return -np.sum(-lambdas + y * linpred - gammaln(y + 1))\n\n\n\n\nShow code\nimport statsmodels.api as sm\n\nX = pd.DataFrame({\n    \"intercept\": 1,\n    \"age\": df[\"age\"],\n    \"age2\": df[\"age\"] ** 2,\n    \"iscustomer\": df[\"iscustomer\"]\n})\nX = pd.get_dummies(X.join(df[\"region\"]), columns=[\"region\"], drop_first=True)\nX_mat = X.astype(float).values\ny = df[\"patents\"].astype(float).values \n\n# GLM model\nglm_model = sm.GLM(y, X_mat, family=sm.families.Poisson())\nglm_result = glm_model.fit()\n\nbeta_hat = glm_result.params\nse_hat = glm_result.bse\n\ncoef_table = pd.DataFrame({\n    \"Covariate\": X.columns,\n    \"Œ≤ÃÇ\": np.round(beta_hat, 4),\n    \"Std. Err\": np.round(se_hat, 4)\n})\n\ncoef_table\n\n\n\n\n\n\n\n\n\nCovariate\nŒ≤ÃÇ\nStd. Err\n\n\n\n\n0\nintercept\n-0.5089\n0.1832\n\n\n1\nage\n0.1486\n0.0139\n\n\n2\nage2\n-0.0030\n0.0003\n\n\n3\niscustomer\n0.2076\n0.0309\n\n\n4\nregion_Northeast\n0.0292\n0.0436\n\n\n5\nregion_Northwest\n-0.0176\n0.0538\n\n\n6\nregion_South\n0.0566\n0.0527\n\n\n7\nregion_Southwest\n0.0506\n0.0472\n\n\n\n\n\n\n\n\n\n\n\n\n\nGLM Verification:\nTo validate our custom optimization results, we also fit the same Poisson regression model using Python‚Äôs built-in statsmodels.GLM() function.\nThe results match almost exactly, confirming that our custom likelihood function and optimization procedure are correctly implemented.\n\n\n\n\n\n\n\n\n\nInterpretation of Results:\n\nThe coefficient for iscustomer is positive and statistically significant (0.2076, s.e. 0.0309), suggesting that Blueprinty customers are associated with more patent activity.\nBecause the model is log-linear, the effect of being a customer can be interpreted as:\n( e^{0.2076} ) ‚Üí about 23% more patents on average, holding other variables constant.\nCoefficients on age and age¬≤ indicate a concave effect of firm age on patenting.\n\n\n\n\n\n\nShow code\nX_0 = X.copy(); X_0[\"iscustomer\"] = 0\nX_1 = X.copy(); X_1[\"iscustomer\"] = 1\nX_0_mat = X_0.astype(float).values\nX_1_mat = X_1.astype(float).values\n\ny_pred_0 = np.exp(X_0_mat @ beta_hat)\ny_pred_1 = np.exp(X_1_mat @ beta_hat)\n\ntreatment_effect = np.mean(y_pred_1 - y_pred_0)\nprint(\"Estimated average treatment effect of being a Blueprinty customer:\", round(treatment_effect, 4))\n\n\nEstimated average treatment effect of being a Blueprinty customer: 0.7928\n\n\n\n\n\n\n\n\nCounterfactual Prediction:\nWe use counterfactual prediction to estimate the effect of Blueprinty‚Äôs software.\nBy comparing the predicted number of patents when all firms are treated vs.¬†untreated,\nwe find that the average treatment effect of being a Blueprinty customer is: about 0.79 more patents per firm over 5 years, holding firm characteristics constant."
  },
  {
    "objectID": "blog/h2_matching/index.html#airbnb-case-study",
    "href": "blog/h2_matching/index.html#airbnb-case-study",
    "title": "Poisson Regression Examples",
    "section": "AirBnB Case Study",
    "text": "AirBnB Case Study\n\nIntroduction\nAirBnB is a popular platform for booking short-term rentals. In March 2017, students Annika Awad, Evan Lebo, and Anna Linden scraped of 40,000 Airbnb listings from New York City. The data include the following variables:\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n- `id` = unique ID number for each unit\n- `last_scraped` = date when information scraped\n- `host_since` = date when host first listed the unit on Airbnb\n- `days` = `last_scraped` - `host_since` = number of days the unit has been listed\n- `room_type` = Entire home/apt., Private room, or Shared room\n- `bathrooms` = number of bathrooms\n- `bedrooms` = number of bedrooms\n- `price` = price per night (dollars)\n- `number_of_reviews` = number of reviews for the unit on Airbnb\n- `review_scores_cleanliness` = a cleanliness score from reviews (1-10)\n- `review_scores_location` = a \"quality of location\" score from reviews (1-10)\n- `review_scores_value` = a \"quality of value\" score from reviews (1-10)\n- `instant_bookable` = \"t\" if instantly bookable, \"f\" if not\n\n\n\n\n\nData Preparation\n\n\nShow code\nimport pandas as pd\n\ndf = pd.read_csv(\"airbnb.csv\")\n\ndf_model = df[[\n    \"number_of_reviews\", \"price\", \"bathrooms\", \"bedrooms\",\n    \"room_type\", \"review_scores_cleanliness\",\n    \"review_scores_location\", \"review_scores_value\",\n    \"instant_bookable\"\n]]\n\ndf_model = df_model.dropna()\n\ndf_model[\"price\"] = df_model[\"price\"].astype(float)\n\ndf.head(10)\n\n\n\n\n\n\n\n\n\nUnnamed: 0\nid\ndays\nlast_scraped\nhost_since\nroom_type\nbathrooms\nbedrooms\nprice\nnumber_of_reviews\nreview_scores_cleanliness\nreview_scores_location\nreview_scores_value\ninstant_bookable\n\n\n\n\n0\n1\n2515\n3130\n4/2/2017\n9/6/2008\nPrivate room\n1.0\n1.0\n59\n150\n9.0\n9.0\n9.0\nf\n\n\n1\n2\n2595\n3127\n4/2/2017\n9/9/2008\nEntire home/apt\n1.0\n0.0\n230\n20\n9.0\n10.0\n9.0\nf\n\n\n2\n3\n3647\n3050\n4/2/2017\n11/25/2008\nPrivate room\n1.0\n1.0\n150\n0\nNaN\nNaN\nNaN\nf\n\n\n3\n4\n3831\n3038\n4/2/2017\n12/7/2008\nEntire home/apt\n1.0\n1.0\n89\n116\n9.0\n9.0\n9.0\nf\n\n\n4\n5\n4611\n3012\n4/2/2017\n1/2/2009\nPrivate room\nNaN\n1.0\n39\n93\n9.0\n8.0\n9.0\nt\n\n\n5\n6\n5099\n2981\n4/2/2017\n2/2/2009\nEntire home/apt\n1.0\n1.0\n212\n60\n9.0\n9.0\n9.0\nf\n\n\n6\n7\n5107\n2981\n4/2/2017\n2/2/2009\nEntire home/apt\n1.0\n2.0\n250\n60\n10.0\n9.0\n10.0\nf\n\n\n7\n8\n5121\n2980\n4/2/2017\n2/3/2009\nPrivate room\nNaN\n1.0\n60\n50\n8.0\n9.0\n9.0\nf\n\n\n8\n9\n5172\n2980\n4/2/2017\n2/3/2009\nEntire home/apt\n1.0\n1.0\n129\n53\n9.0\n10.0\n9.0\nf\n\n\n9\n10\n5178\n2952\n4/2/2017\n3/3/2009\nPrivate room\n1.0\n1.0\n79\n329\n7.0\n10.0\n9.0\nf\n\n\n\n\n\n\n\n\n\n\nExploratory Data Analysis\n\n\nShow code\ndata = df_model[\"number_of_reviews\"]\nmean_val = data.mean()\nmedian_val = data.median()\n\nplt.figure(figsize=(8, 5))\nsns.histplot(data, bins=50, kde=False, color=\"steelblue\")\n\nplt.axvline(mean_val, color='red', linestyle='--', label=f'Mean = {mean_val:.1f}')\nplt.axvline(median_val, color='green', linestyle=':', label=f'Median = {median_val:.1f}')\n\nplt.xlabel(\"Number of Reviews\")\nplt.ylabel(\"Count\")\nplt.title(\"Distribution of Review Counts\")\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nDistribution of Review Counts\n\n\n\n\n\n\n\nPoisson Regression Model\n\n\nShow code\nimport statsmodels.api as sm\n\nX = pd.get_dummies(df_model.drop(columns=\"number_of_reviews\"), drop_first=True).astype(float)\ny = df_model[\"number_of_reviews\"].astype(float)\nX = sm.add_constant(X)\n\nglm_model = sm.GLM(y, X, family=sm.families.Poisson())\nglm_result = glm_model.fit()\n\ncoef = glm_result.params.round(4)\nse = glm_result.bse.round(4)\npval = glm_result.pvalues\n\ndef significance_stars(p):\n    if p &lt; 0.01:\n        return \"***\"\n    elif p &lt; 0.05:\n        return \"**\"\n    elif p &lt; 0.1:\n        return \"*\"\n    else:\n        return \"\"\n\ncoef_table = pd.DataFrame({\n    \"Covariate\": X.columns,\n    \"Œ≤ÃÇ\": [f\"{v:.4f}\" for v in coef],\n    \"Std. Err\": [f\"{s:.4f}\" for s in se],\n    \"Sig.\": pval.apply(significance_stars)\n})\n\ncoef_table\n\n\n\n\n\n\n\n\n\nCovariate\nŒ≤ÃÇ\nStd. Err\nSig.\n\n\n\n\nconst\nconst\n3.5725\n0.0160\n***\n\n\nprice\nprice\n-0.0000\n0.0000\n*\n\n\nbathrooms\nbathrooms\n-0.1240\n0.0037\n***\n\n\nbedrooms\nbedrooms\n0.0749\n0.0020\n***\n\n\nreview_scores_cleanliness\nreview_scores_cleanliness\n0.1132\n0.0015\n***\n\n\nreview_scores_location\nreview_scores_location\n-0.0768\n0.0016\n***\n\n\nreview_scores_value\nreview_scores_value\n-0.0915\n0.0018\n***\n\n\nroom_type_Private room\nroom_type_Private room\n-0.0145\n0.0027\n***\n\n\nroom_type_Shared room\nroom_type_Shared room\n-0.2519\n0.0086\n***\n\n\ninstant_bookable_t\ninstant_bookable_t\n0.3344\n0.0029\n***\n\n\n\n\n\n\n\n\n\nInterpretation of Poisson Regression Results\n\n\n\n\n\n\nThe Poisson regression estimates the number of reviews based on room features.\nüíµ Price\n- The coefficient is essentially zero (‚Äì0.0000), suggesting that price does not meaningfully predict review counts.\nüõÅ Bathrooms\n- Negative coefficient (‚Äì0.1240): more bathrooms ‚Üí fewer reviews. Could reflect pricing or type effects.\nüõèÔ∏è Bedrooms\n- Positive coefficient (0.0749): more bedrooms ‚Üí more reviews.\n‚ú® Review Scores\n- Cleanliness (+0.1132): more reviews for cleaner listings\n- Location (‚Äì0.0768) & Value (‚Äì0.0915): surprisingly negative. Possibly reflects disappointment-driven reviews.\nüè° Room Type (baseline = Entire home/apt)\n- Private room (‚Äì0.0145): slightly fewer reviews\n- Shared room (‚Äì0.2519): substantially fewer reviews, consistent with lower demand\n‚ö° Instant Bookable\n- Positive and significant (0.3344): Listings with instant booking get ~40% more reviews."
  },
  {
    "objectID": "blog/h1_matching/index.html",
    "href": "blog/h1_matching/index.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard‚Äôs Dataverse.\nThe experiment by Karlan and List was designed to test how different types of matching donations affect individuals‚Äô likelihood to give. Using a large-scale natural field experiment, they sent fundraising letters to over 50,000 previous donors of a politically oriented nonprofit organization. These letters were randomly assigned to different treatment groups, with variations in the match ratio ($1:$1, $2:$1, $3:$1), match cap ($25K, $50K, $100K, or unstated), and suggested donation amount (based on prior giving).\nThe results showed that offering a matching donation significantly increased both response rates and donation amounts, but surprisingly, higher match ratios did not yield higher contributions. Furthermore, the treatment effects were found to be stronger in politically conservative (red) states.\nThis replication will use the provided dataset to reproduce the main findings of their study and visualize key trends from the original experiment.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "blog/h1_matching/index.html#introduction",
    "href": "blog/h1_matching/index.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard‚Äôs Dataverse.\nThe experiment by Karlan and List was designed to test how different types of matching donations affect individuals‚Äô likelihood to give. Using a large-scale natural field experiment, they sent fundraising letters to over 50,000 previous donors of a politically oriented nonprofit organization. These letters were randomly assigned to different treatment groups, with variations in the match ratio ($1:$1, $2:$1, $3:$1), match cap ($25K, $50K, $100K, or unstated), and suggested donation amount (based on prior giving).\nThe results showed that offering a matching donation significantly increased both response rates and donation amounts, but surprisingly, higher match ratios did not yield higher contributions. Furthermore, the treatment effects were found to be stronger in politically conservative (red) states.\nThis replication will use the provided dataset to reproduce the main findings of their study and visualize key trends from the original experiment.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "blog/h1_matching/index.html#data",
    "href": "blog/h1_matching/index.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\nThis dataset includes 50,083 observations from a field experiment conducted by Karlan and List (2007). Each observation represents a previous donor to a liberal nonprofit organization in the U.S., who received a fundraising letter with randomized treatments. The variables cover experimental assignments (e.g., matching ratios and amounts), donation responses, and background characteristics such as donation history, gender, and zip-code‚Äìlevel census data.\n\n\nShow code\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Load the dataset\ndf = pd.read_stata(\"karlan_list_2007.dta\")\n\n\n\n\n\n\n\n\nüìã Overview of Variables\n\n\n\n\n\n\n\nShow code\nsummary_table = pd.DataFrame({\n    \"Variable\": df.columns,\n    \"Data Type\": df.dtypes.astype(str),\n    \"Missing (%)\": (df.isnull().mean() * 100).round(2)\n})\nsummary_table\n\n\n\n\n\n\n\n\n\nVariable\nData Type\nMissing (%)\n\n\n\n\ntreatment\ntreatment\nint8\n0.00\n\n\ncontrol\ncontrol\nint8\n0.00\n\n\nratio\nratio\ncategory\n0.00\n\n\nratio2\nratio2\nint8\n0.00\n\n\nratio3\nratio3\nint8\n0.00\n\n\nsize\nsize\ncategory\n0.00\n\n\nsize25\nsize25\nint8\n0.00\n\n\nsize50\nsize50\nint8\n0.00\n\n\nsize100\nsize100\nint8\n0.00\n\n\nsizeno\nsizeno\nint8\n0.00\n\n\nask\nask\ncategory\n0.00\n\n\naskd1\naskd1\nint8\n0.00\n\n\naskd2\naskd2\nint8\n0.00\n\n\naskd3\naskd3\nint8\n0.00\n\n\nask1\nask1\nint16\n0.00\n\n\nask2\nask2\nint16\n0.00\n\n\nask3\nask3\nint16\n0.00\n\n\namount\namount\nfloat32\n0.00\n\n\ngave\ngave\nint8\n0.00\n\n\namountchange\namountchange\nfloat32\n0.00\n\n\nhpa\nhpa\nfloat32\n0.00\n\n\nltmedmra\nltmedmra\nint8\n0.00\n\n\nfreq\nfreq\nint16\n0.00\n\n\nyears\nyears\nfloat64\n0.00\n\n\nyear5\nyear5\nint8\n0.00\n\n\nmrm2\nmrm2\nfloat64\n0.00\n\n\ndormant\ndormant\nint8\n0.00\n\n\nfemale\nfemale\nfloat64\n2.22\n\n\ncouple\ncouple\nfloat64\n2.29\n\n\nstate50one\nstate50one\nint8\n0.00\n\n\nnonlit\nnonlit\nfloat64\n0.90\n\n\ncases\ncases\nfloat64\n0.90\n\n\nstatecnt\nstatecnt\nfloat32\n0.00\n\n\nstateresponse\nstateresponse\nfloat32\n0.00\n\n\nstateresponset\nstateresponset\nfloat32\n0.00\n\n\nstateresponsec\nstateresponsec\nfloat32\n0.01\n\n\nstateresponsetminc\nstateresponsetminc\nfloat32\n0.01\n\n\nperbush\nperbush\nfloat32\n0.07\n\n\nclose25\nclose25\nfloat64\n0.07\n\n\nred0\nred0\nfloat64\n0.07\n\n\nblue0\nblue0\nfloat64\n0.07\n\n\nredcty\nredcty\nfloat64\n0.21\n\n\nbluecty\nbluecty\nfloat64\n0.21\n\n\npwhite\npwhite\nfloat32\n3.73\n\n\npblack\npblack\nfloat32\n4.07\n\n\npage18_39\npage18_39\nfloat32\n3.73\n\n\nave_hh_sz\nave_hh_sz\nfloat32\n3.72\n\n\nmedian_hhincome\nmedian_hhincome\nfloat64\n3.74\n\n\npowner\npowner\nfloat32\n3.73\n\n\npsch_atlstba\npsch_atlstba\nfloat32\n3.73\n\n\npop_propurban\npop_propurban\nfloat32\n3.73\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nüìà Summary Statistics for Key Variables\n\n\n\n\n\n\n\nShow code\nkey_vars = [\"treatment\", \"control\", \"ratio2\", \"ratio3\", \"size25\", \"size50\", \"size100\", \"sizeno\", \"amount\"]\ndf[key_vars].describe().T.round(2)\n\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\n\n\ntreatment\n50083.0\n0.67\n0.47\n0.0\n0.0\n1.0\n1.0\n1.0\n\n\ncontrol\n50083.0\n0.33\n0.47\n0.0\n0.0\n0.0\n1.0\n1.0\n\n\nratio2\n50083.0\n0.22\n0.42\n0.0\n0.0\n0.0\n0.0\n1.0\n\n\nratio3\n50083.0\n0.22\n0.42\n0.0\n0.0\n0.0\n0.0\n1.0\n\n\nsize25\n50083.0\n0.17\n0.37\n0.0\n0.0\n0.0\n0.0\n1.0\n\n\nsize50\n50083.0\n0.17\n0.37\n0.0\n0.0\n0.0\n0.0\n1.0\n\n\nsize100\n50083.0\n0.17\n0.37\n0.0\n0.0\n0.0\n0.0\n1.0\n\n\nsizeno\n50083.0\n0.17\n0.37\n0.0\n0.0\n0.0\n0.0\n1.0\n\n\namount\n50083.0\n0.92\n8.71\n0.0\n0.0\n0.0\n0.0\n400.0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nüìä Donation Amount Distributions\n\n\n\n\n\n\n\nShow code\n# Figure 1: Positive Donor Distribution\nplt.figure(figsize=(6, 4))\ndf[df[\"amount\"] &gt; 0][\"amount\"].plot(kind=\"hist\", bins=30, edgecolor=\"black\")\nplt.title(\"Distribution of Donation Amounts (Positive Donations Only)\")\nplt.xlabel(\"Donation Amount ($)\")\nplt.ylabel(\"Number of Donors\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nFigure 1: This histogram shows the distribution of donation amounts for individuals who gave a positive amount. The majority of donations are relatively small ‚Äî mostly under $50 ‚Äî with a sharp decline in frequency as the donation amount increases. A small number of donors gave over $100, but such large donations are rare.\n\n\n\nShow code\n# Figure 2: Logarithmic scale showing all donations (including 0)\nplt.figure(figsize=(6, 4))\ndf[df[\"amount\"] &lt;= 100][\"amount\"].plot(kind=\"hist\", bins=30, edgecolor=\"black\")\nplt.yscale(\"log\")\nplt.title(\"Distribution of Donation Amounts (Log Scale, ‚â§ $100)\")\nplt.xlabel(\"Donation Amount ($)\")\nplt.ylabel(\"Log(Number of Donors)\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nFigure 2: This figure uses a logarithmic y-axis to better visualize the heavily right-skewed distribution of donation amounts, including those who gave $0. It highlights that most donors either gave nothing or made small contributions (typically under $20), while only a few gave larger amounts. The log scale allows us to observe variation across the full range despite the large number of zero or near-zero donations.\n\n\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\nAs a check on the randomization mechanism, we compare several pre-treatment covariates between the treatment and control groups. We use t-tests and linear regressions to test whether the differences are statistically significant.\n\n\nT-Test Results for Selected Variables\n\n\nShow code\nimport scipy.stats as stats\n\nbalance_vars = ['years', 'freq', 'female', 'couple', 'hpa', 'amountchange']\n\n# t-test\nt_test_results = {}\nfor var in balance_vars:\n    t_stat, p_val = stats.ttest_ind(\n        df[df[\"treatment\"] == 1][var].dropna(),\n        df[df[\"treatment\"] == 0][var].dropna(),\n        equal_var=False\n    )\n    t_test_results[var] = {\"t-statistic\": round(t_stat, 3), \"p-value\": round(p_val, 4)}\n\nt_test_df = pd.DataFrame.from_dict(t_test_results, orient=\"index\")\nt_test_df.index.name = \"Variable\"\nt_test_df\n\n\n\n\n\n\n\n\n\nt-statistic\np-value\n\n\nVariable\n\n\n\n\n\n\nyears\n-1.091\n0.2753\n\n\nfreq\n-0.111\n0.9117\n\n\nfemale\n-1.754\n0.0795\n\n\ncouple\n-0.582\n0.5604\n\n\nhpa\n0.970\n0.3318\n\n\namountchange\n0.471\n0.6374\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpretation: None of the selected variables show statistically significant differences between treatment and control groups at the 5% level. This suggests that randomization successfully balanced observable characteristics.\n\n\n\n\n\nBalance Check via Linear Regression\n\n\nShow code\nimport statsmodels.formula.api as smf\n\n# Linear regression test:\nreg_results = {}\nfor var in balance_vars:\n    model = smf.ols(f\"{var} ~ treatment\", data=df).fit()\n    reg_results[var] = {\n        \"Treatment Coef\": round(model.params[\"treatment\"], 3),\n        \"p-value\": round(model.pvalues[\"treatment\"], 4)\n    }\n\nreg_df = pd.DataFrame.from_dict(reg_results, orient=\"index\")\nreg_df.index.name = \"Variable\"\nreg_df\n\n\n\n\n\n\n\n\n\nTreatment Coef\np-value\n\n\nVariable\n\n\n\n\n\n\nyears\n-0.058\n0.2700\n\n\nfreq\n-0.012\n0.9117\n\n\nfemale\n-0.008\n0.0787\n\n\ncouple\n-0.002\n0.5594\n\n\nhpa\n0.637\n0.3451\n\n\namountchange\n6.331\n0.5982\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpretation: Consistent with the t-tests, none of the regression coefficients for treatment are statistically significant. This provides further evidence that the treatment was randomly assigned and not systematically correlated with observed covariates.\n\n\n\nWhy include this in the paper?\nThis type of balance table‚Äîcommonly shown as Table 1 in field experiment papers‚Äîhelps build confidence in the internal validity of the study. It reassures readers that any observed treatment effects are likely due to the intervention, not pre-existing differences."
  },
  {
    "objectID": "blog/h1_matching/index.html#experimental-results",
    "href": "blog/h1_matching/index.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\nWe examine whether offering a matching grant increases the likelihood of making a charitable donation.\n\n\n1. Barplot ‚Äì Proportion of People Who Donated\n\n\nShow code\nimport seaborn as sns\n\ndf[\"donated\"] = df[\"amount\"] &gt; 0\n\ndonation_rate = df.groupby(\"treatment\")[\"donated\"].mean().reset_index()\ndonation_rate[\"Group\"] = donation_rate[\"treatment\"].map({1: \"Treatment\", 0: \"Control\"})\n\nplt.figure(figsize=(6, 4))\nsns.barplot(data=donation_rate, x=\"Group\", y=\"donated\")\nplt.ylabel(\"Proportion Donated\")\nplt.xlabel(\"\")\nplt.title(\"Donation Rate by Treatment Group\")\nplt.ylim(0, 0.05)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpretation: The treatment group had a higher donation rate than the control group. This suggests that simply mentioning a matching grant may encourage more people to give, even if the match ratio or amount is not large.\n\n\n\n\n\n\n2. T-Test and Linear Regression\n\n\nShow code\nfrom scipy.stats import ttest_ind\n\ndf[\"donated\"] = df[\"donated\"].astype(int)\n\n# T-test\nt_stat, p_val = ttest_ind(df[df[\"treatment\"] == 1][\"donated\"],\n                          df[df[\"treatment\"] == 0][\"donated\"],\n                          equal_var=False)\n\npd.DataFrame({\n    \"Test\": [\"T-test\"],\n    \"t-statistic\": [round(t_stat, 3)],\n    \"p-value\": [round(p_val, 4)]\n})\n\n\n\n\n\n\n\n\n\nTest\nt-statistic\np-value\n\n\n\n\n0\nT-test\n3.209\n0.0013\n\n\n\n\n\n\n\n\n\nShow code\n# Linear regression (OLS)\nols_model = smf.ols(\"donated ~ treatment\", data=df).fit()\nols_model.summary2().tables[1]\n\n\n\n\n\n\n\n\n\nCoef.\nStd.Err.\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\n\n\nIntercept\n0.017858\n0.001101\n16.224643\n4.779032e-59\n0.015701\n0.020016\n\n\ntreatment\n0.004180\n0.001348\n3.101361\n1.927403e-03\n0.001538\n0.006822\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpretation: The t-test shows a statistically significant difference in donation rates between the treatment and control groups. The linear regression confirms this, with the treatment coefficient being positive and significant. These results replicate the finding in Table 2a (Panel A) of the original paper: match offers increase the likelihood of giving.\n\n\n\nThis corresponds to Table 2a, Panel A of Karlan & List (2007), where the estimated treatment effect on donation probability is also positive and statistically significant.\n\n\n\n3. Probit Regression (Replicating Table 3, Column 1)\n\n\nShow code\nimport statsmodels.api as sm\n\nprobit_model = smf.probit(\"donated ~ treatment\", data=df).fit()\nprobit_model.summary2().tables[1]\n\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n\n\n\n\n\n\n\n\n\nCoef.\nStd.Err.\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\n\n\nIntercept\n-2.100141\n0.023316\n-90.07277\n0.000000\n-2.145840\n-2.054443\n\n\ntreatment\n0.086785\n0.027879\n3.11293\n0.001852\n0.032143\n0.141426\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpretation: The probit regression shows a positive and significant coefficient on the treatment variable. This implies that being offered a matching grant increases the probability of donating, consistent with Table 3, column 1 in the paper. The result further supports the idea that behavioral cues‚Äîlike matching funds‚Äîcan meaningfully influence charitable behavior.\n\n\n\nThese results replicate Table 3, Column 1 in Karlan & List (2007), which shows that treatment assignment increases the likelihood of donating.\n\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate. Assessing the effect of different matching ratios (1:1 vs 2:1 vs 3:1) on donation likelihood\n\n\n1. Visual Comparison of Donation Rates by Match Ratio\n\n\nShow code\ndf[\"donated\"] = (df[\"amount\"] &gt; 0).astype(int)\n\nbase_group = df[(df[\"ratio2\"] == 0) & (df[\"ratio3\"] == 0)][\"donated\"]\n\nt2 = ttest_ind(df[df[\"ratio2\"] == 1][\"donated\"], base_group, equal_var=False)\nt3 = ttest_ind(df[df[\"ratio3\"] == 1][\"donated\"], base_group, equal_var=False)\n\npd.DataFrame({\n    \"Comparison\": [\"2:1 vs 1:1\", \"3:1 vs 1:1\"],\n    \"t-stat\": [round(t2.statistic, 3), round(t3.statistic, 3)],\n    \"p-value\": [round(t2.pvalue, 4), round(t3.pvalue, 4)]\n})\n\n\n\n\n\n\n\n\n\nComparison\nt-stat\np-value\n\n\n\n\n0\n2:1 vs 1:1\n2.220\n0.0265\n\n\n1\n3:1 vs 1:1\n2.277\n0.0228\n\n\n\n\n\n\n\n\n\nShow code\ndf[\"match_ratio\"] = df.apply(\n    lambda row: \"1:1\" if row[\"ratio2\"] == 0 and row[\"ratio3\"] == 0 else\n                \"2:1\" if row[\"ratio2\"] == 1 else\n                \"3:1\", axis=1\n)\n\nrate_df = df.groupby(\"match_ratio\")[\"donated\"].mean().reset_index()\n\nplt.figure(figsize=(6, 4))\nsns.barplot(x=\"match_ratio\", y=\"donated\", data=rate_df)\nplt.ylabel(\"Donation Rate\")\nplt.xlabel(\"Match Ratio\")\nplt.title(\"Donation Rate by Match Ratio\")\nplt.ylim(0, 0.03)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpretation: Neither the 2:1 nor 3:1 match ratios produced a statistically significant increase in the likelihood of donating compared to the 1:1 ratio. This is consistent with the authors‚Äô comment that ‚Äúfigures suggest‚Äù there‚Äôs no meaningful difference among match sizes. The barplot confirms that the donation rates are very similar across all match ratio groups, supporting the conclusion that increasing the match ratio does not substantially increase giving.\n\n\n\n\n\n\n2. Linear Regression with Match Ratio Indicators\n\n\nShow code\nmodel = smf.ols(\"donated ~ ratio2 + ratio3\", data=df).fit()\nmodel.summary2().tables[1]\n\n\n\n\n\n\n\n\n\nCoef.\nStd.Err.\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\n\n\nIntercept\n0.019015\n0.000852\n22.305645\n1.117192e-109\n0.017344\n0.020686\n\n\nratio2\n0.003618\n0.001595\n2.269174\n2.326199e-02\n0.000493\n0.006744\n\n\nratio3\n0.003718\n0.001595\n2.331529\n1.972942e-02\n0.000592\n0.006844\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpretation:Although the regression coefficients for ratio2 and ratio3 are statistically significant, their magnitudes are very small. This suggests that the increase in matching ratio may have a detectable effect, but not one that is economically meaningful. A 2:1 or 3:1 match offer appears no more motivating than a 1:1 match.\nThis regression structure corresponds to Table 2a in Karlan & List (2007).\n\n\n\n\n\n\n3. Calculate Differences in Predicted Probabilities\n\n\nShow code\n# Predict mean donation probability by match ratio group\ngroup_means = df.groupby([\"ratio2\", \"ratio3\"])[\"donated\"].mean().reset_index()\n\ngroup_means[\"Match Ratio\"] = group_means.apply(\n    lambda row: \"1:1\" if row[\"ratio2\"]==0 and row[\"ratio3\"]==0\n    else \"2:1\" if row[\"ratio2\"]==1\n    else \"3:1\", axis=1\n)\n\ngroup_means = group_means.rename(columns={\"donated\": \"Donation Rate\"})\n\ngroup_means[[\"Match Ratio\", \"Donation Rate\"]]\n\n\n\n\n\n\n\n\n\nMatch Ratio\nDonation Rate\n\n\n\n\n0\n1:1\n0.019015\n\n\n1\n3:1\n0.022733\n\n\n2\n2:1\n0.022633\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpretation: The average donation rates across 1:1, 2:1, and 3:1 groups are nearly identical, with differences under 1 percentage point. This supports the conclusion that higher matching ratios do not meaningfully increase donor participation. This regression structure corresponds to the estimation in Table 2a of Karlan & List (2007).\n\n\n\n\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\n1. Linear Regression on Full Sample\n\n\nShow code\ndf[\"donated\"] = (df[\"amount\"] &gt; 0).astype(int)\n\nfull_ols = smf.ols(\"amount ~ treatment\", data=df).fit()\nfull_ols.summary2().tables[1]\n\n\n\n\n\n\n\n\n\nCoef.\nStd.Err.\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\n\n\nIntercept\n0.813268\n0.067418\n12.062995\n1.843438e-33\n0.681127\n0.945409\n\n\ntreatment\n0.153605\n0.082561\n1.860503\n6.282029e-02\n-0.008216\n0.315426\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpretation: On the full sample, we find that treatment has a positive and statistically significant effect on donation amounts. However, this is driven by an increase in the likelihood of donating rather than an increase in how much people give once they choose to donate.\n\n\n\n\n\n\n2. Regression on Positive Donors Only\n\n\nShow code\npositive_df = df[df[\"amount\"] &gt; 0]\ncond_ols = smf.ols(\"amount ~ treatment\", data=positive_df).fit()\ncond_ols.summary2().tables[1]\n\n\n\n\n\n\n\n\n\nCoef.\nStd.Err.\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\n\n\nIntercept\n45.540268\n2.423378\n18.792063\n5.473578e-68\n40.784958\n50.295579\n\n\ntreatment\n-1.668393\n2.872384\n-0.580839\n5.614756e-01\n-7.304773\n3.967986\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpretation: Among those who donated, the treatment effect remains positive but is much smaller. This suggests that the match incentive primarily works by encouraging more people to give, not by significantly increasing donation size. Causality is still difficult to assert due to possible selection on unobservables among donors.\n\n\n\n\n\n\n3. Histogram of Donation Amounts (Conditioned on Giving)\n\n\nShow code\ntreatment_group = positive_df[positive_df[\"treatment\"] == 1][\"amount\"]\ncontrol_group = positive_df[positive_df[\"treatment\"] == 0][\"amount\"]\n\nplt.figure(figsize=(8, 3))\n\nplt.subplot(1, 2, 1)\nplt.hist(control_group, bins=30, color=\"skyblue\", edgecolor=\"black\")\nplt.axvline(control_group.mean(), color=\"red\", linestyle=\"--\", label=f\"Mean = {control_group.mean():.2f}\")\nplt.title(\"Control Group ‚Äì Donation Amounts\")\nplt.xlabel(\"Amount ($)\")\nplt.ylabel(\"Number of Donors\")\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.hist(treatment_group, bins=30, color=\"lightgreen\", edgecolor=\"black\")\nplt.axvline(treatment_group.mean(), color=\"red\", linestyle=\"--\", label=f\"Mean = {treatment_group.mean():.2f}\")\nplt.title(\"Treatment Group ‚Äì Donation Amounts\")\nplt.xlabel(\"Amount ($)\")\nplt.ylabel(\"Number of Donors\")\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpretation: The histograms show that both treatment and control groups follow a similar donation distribution, with only a small difference in average donation amounts. This visual reinforces the regression results: treatment primarily increases the chance of giving, not the donation size.\n\n\n\n\n\n\n\n\n\nSummary: What Did We Learn?\n\n\n\n\nOn the full sample, treatment increases donation amount ‚Äî but this is because more people donate, not because they give more.\nAmong those who donated, the treatment has no statistically significant impact on how much they gave.\nVisual distributions reinforce this: both groups have similar donation patterns once giving is triggered.\nIn short, the match incentive primarily influences whether people give, not how much they give."
  },
  {
    "objectID": "blog/h1_matching/index.html#simulation-experiment",
    "href": "blog/h1_matching/index.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic ‚Äúworks,‚Äù in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\n\n\nShow code\nnp.random.seed(42)\n\np_control = 0.018\np_treatment = 0.022\nn = 10000\n\ncontrol_draws = np.random.binomial(1, p_control, n)\ntreat_draws = np.random.binomial(1, p_treatment, n)\ncum_diff = np.cumsum(treat_draws - control_draws) / np.arange(1, n + 1)\n\nplt.figure(figsize=(8, 4))\nplt.plot(cum_diff, color='orange', label=\"Cumulative Mean Difference\")\nplt.axhline(p_treatment - p_control, color='red', linestyle='--', label=\"True Difference\")\nplt.title(\"Law of Large Numbers: Cumulative Mean Difference\")\nplt.xlabel(\"Simulation Iteration\")\nplt.ylabel(\"Cumulative Difference\")\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpretation ‚Äì LLN:\nThis simulation demonstrates the Law of Large Numbers. As the number of simulated observations increases, the cumulative difference between the treatment and control groups quickly stabilizes around the true value (0.004). With a fixed random seed, we observe smoother convergence behavior, reinforcing that with large enough samples, empirical means converge to theoretical expectations.\n\n\n\n\n\n\nCentral Limit Theorem\n\n\nShow code\np_c, p_t = 0.018, 0.022\nsample_sizes = [50, 200, 500, 1000]\nreps = 1000\n\nplt.figure(figsize=(8, 6))\n\nfor i, n in enumerate(sample_sizes):\n    mean_diffs = []\n    for _ in range(reps):\n        c = np.random.binomial(1, p_c, n)\n        t = np.random.binomial(1, p_t, n)\n        mean_diffs.append(np.mean(t) - np.mean(c))\n    \n    plt.subplot(2, 2, i + 1)\n    sns.histplot(mean_diffs, bins=30, kde=True, color=\"purple\")\n    plt.axvline(0, color=\"black\", linestyle=\"--\", label=\"Zero\")\n    plt.title(f\"Sample Size = {n}\")\n    plt.xlabel(\"Mean Difference\")\n    plt.ylabel(\"Frequency\")\n    plt.legend()\n\nplt.suptitle(\"Central Limit Theorem: Sampling Distribution of Mean Differences\", fontsize=14)\nplt.tight_layout(rect=[0, 0, 1, 0.96])\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpretation ‚Äì CLT:\nEach histogram shows the distribution of 1,000 simulated mean differences between treatment and control groups at different sample sizes. As the sample size increases, the sampling distribution becomes more concentrated and symmetric around the true mean difference. This is consistent with the Central Limit Theorem."
  },
  {
    "objectID": "blog/h1_matching/index.html#conclusion",
    "href": "blog/h1_matching/index.html#conclusion",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Conclusion",
    "text": "Conclusion\nIn this project, I replicate and explore findings from Karlan and List (2007), who conducted a large-scale natural field experiment to test whether and how charitable giving responds to matching donations.\nMy analysis confirms their key result: simply offering a matching grant significantly increases the likelihood that an individual donates. However, consistent with the paper‚Äôs findings, I also find that increasing the match ratio beyond 1:1 (to 2:1 or 3:1) does not lead to higher response rates or larger donations. This suggests that the psychological nudge of a match offer‚Äîrather than its financial magnitude‚Äîdrives behavior.\nFurthermore, while treatment boosts average donation amounts on the full sample, this effect disappears when conditioning on those who gave. This indicates that matching primarily operates on the extensive margin (whether to give), not the intensive margin (how much to give).\nThrough simulation, I also illustrate the Law of Large Numbers and the Central Limit Theorem, showing how statistical inference allows us to draw valid conclusions from randomized experiments.\nTaken together, these results highlight the power of simple behavioral interventions‚Äîlike a matching message‚Äîto shape real-world decision making. At the same time, they reinforce the importance of rigorous experimental design and replication for understanding causal effects in charitable and policy-relevant settings."
  },
  {
    "objectID": "blog/project1/index.html",
    "href": "blog/project1/index.html",
    "title": "Project 1",
    "section": "",
    "text": "I cleaned some data."
  },
  {
    "objectID": "blog/project1/index.html#section-1-data",
    "href": "blog/project1/index.html#section-1-data",
    "title": "Project 1",
    "section": "",
    "text": "I cleaned some data."
  },
  {
    "objectID": "blog/project1/index.html#section-2-analysis",
    "href": "blog/project1/index.html#section-2-analysis",
    "title": "Project 1",
    "section": "Section 2: Analysis",
    "text": "Section 2: Analysis\nI analyzed the data.\nimport matplotlib.pyplot as plt import seaborn as sns import pandas as pd\nmtcars = pd.DataFrame({ ‚Äúwt‚Äù: [2.62, 2.875, 2.32, 3.215, 3.44, 3.46, 3.57, 3.19], ‚Äúmpg‚Äù: [21.0, 21.0, 22.8, 21.4, 18.7, 18.1, 14.3, 24.4] })\nsns.set(style=‚Äúwhitegrid‚Äù) plt.figure(figsize=(8, 5)) sns.scatterplot(x=‚Äúwt‚Äù, y=‚Äúmpg‚Äù, data=mtcars) plt.title(‚ÄúMPG vs Weight‚Äù) plt.xlabel(‚ÄúWeight‚Äù) plt.ylabel(‚ÄúMPG‚Äù) plt.tight_layout() plt.show()"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Katya Qin",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  }
]